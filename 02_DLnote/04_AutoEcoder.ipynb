{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torchvision \n",
    "import torch.nn.functional as F \n",
    "from torch import nn, optim \n",
    "from torchvision import transforms, datasets \n",
    "import matplotlib.pyplot as plt \n",
    "from mpl_toolkits.mplot3d import Axes3D # 3차원 플롯을 그리는 용도\n",
    "from matplotlib import cm # 데이터포인트 색상\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# 하이퍼파라미터 준비 \n",
    "EPOCH = 10 \n",
    "BATCH_SIZE = 64 \n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n",
    "print(\"Using Device:\", DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fashion MNIST 데이터셋 불러오기 (학습데이터만 사용) \n",
    "trainset = datasets.FashionMNIST( \n",
    "\t\t\t\t\t\t\t\troot = './data/', \n",
    "\t\t\t\t\t\t\t\ttrain = True, \n",
    "\t\t\t\t\t\t\t\tdownload = True, \n",
    "\t\t\t\t\t\t\t\ttransform = transforms.ToTensor()\n",
    "\t\t\t\t\t\t\t)\n",
    "train_loader = torch.utils.data.DataLoader( \n",
    "\t\t\t\t\t\t\t\tdataset = trainset, \n",
    "\t\t\t\t\t\t\t\tbatch_size = BATCH_SIZE, \n",
    "\t\t\t\t\t\t\t\tshuffle = True, \n",
    "\t\t\t\t\t\t\t\tnum_workers = 2 \n",
    "\t\t\t\t\t\t\t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 오토인코더 모듈 정의 \n",
    "class Autoencoder(nn.Module):\n",
    "\tdef __init__(self):\n",
    "\t\tsuper(Autoencoder, self).__init__() \n",
    "\t\tself.encoder = nn.Sequential( \n",
    "\t\t\t\t\t\t\t\t\tnn.Linear(28*28, 128), \n",
    "\t\t\t\t\t\t\t\t\tnn.ReLU(), \n",
    "\t\t\t\t\t\t\t\t\tnn.Linear(128, 64), \n",
    "\t\t\t\t\t\t\t\t\tnn.ReLU(), \n",
    "\t\t\t\t\t\t\t\t\tnn.Linear(64, 12), \n",
    "\t\t\t\t\t\t\t\t\tnn.ReLU(), \n",
    "\t\t\t\t\t\t\t\t\tnn.Linear(12, 3), \n",
    "\t\t\t\t\t\t\t\t\t# 입력의 특징을 3차원으로 압축\n",
    "\t\t\t\t\t\t\t\t) \n",
    "\t\tself.decoder = nn.Sequential( \n",
    "\t\t\t\t\t\t\t\t\tnn.Linear(3, 12), \n",
    "\t\t\t\t\t\t\t\t\tnn.ReLU(), \n",
    "\t\t\t\t\t\t\t\t\tnn.Linear(12, 64), \n",
    "\t\t\t\t\t\t\t\t\tnn.ReLU(), \n",
    "\t\t\t\t\t\t\t\t\tnn.Linear(64, 128), \n",
    "\t\t\t\t\t\t\t\t\tnn.ReLU(), \n",
    "\t\t\t\t\t\t\t\t\tnn.Linear(128, 28*28), \n",
    "\t\t\t\t\t\t\t\t\tnn.Sigmoid(), \n",
    "\t\t\t\t\t\t\t\t) \n",
    "\tdef forward(self, x): \n",
    "\t\tencoded = self.encoder(x) \n",
    "\t\tdecoded = self.decoder(encoded) \n",
    "\t\treturn encoded, decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = Autoencoder().to(DEVICE) \n",
    "optimizer = torch.optim.Adam(autoencoder.parameters(), lr=0.005)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_data = trainset.data[:5].view(-1, 28*28) \n",
    "view_data = view_data.type(torch.FloatTensor)/255. \n",
    "\n",
    "#픽셀의 색상값이 0~255이므로 모델이 인식하는 0부터 1사이의 값으로 만들기 위해 255로 나눔."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습하기 위한 함수 \n",
    "def train(autoencoder, train_loader): \n",
    "\tautoencoder.train() \n",
    "\tfor step, (x, label) in enumerate(train_loader): \n",
    "\t\toptimizer.zero_grad() \n",
    "\t\tx = x.view(-1, 28*28).to(DEVICE) \n",
    "\t\ty = x.view(-1, 28*28).to(DEVICE) \n",
    "\t\tlabel = label.to(DEVICE) \n",
    "\t\tencoded, decoded = autoencoder(x) \n",
    "\t\tloss = criterion(decoded, y) \n",
    "\t\tloss.backward() \n",
    "\t\toptimizer.step() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1, EPOCH+1): \n",
    "\ttrain(autoencoder, train_loader) \n",
    "\ttest_x = view_data.to(DEVICE) \n",
    "\t_,decoded_data = autoencoder(test_x) \n",
    "\tf, a = plt.subplots(2, 5, figsize=(5, 2)) \n",
    "\tprint(\"[Epoch {}]\".format(epoch)) \n",
    "\tfor i in range(5): \n",
    "\t\timg = np.reshape(view_data.data.numpy()[i],(28, 28)) \n",
    "\t\t#파이토치 텐서를 넘파이로 변환합니다. \n",
    "\t\ta[0][i].imshow(img, cmap='gray') \n",
    "\t\ta[0][i].set_xticks(()) \n",
    "\t\ta[0][i].set_yticks(()) \n",
    "\t\n",
    "\tfor i in range(5): \n",
    "\t\timg = np.reshape(decoded_data.to(\"cpu\").data.numpy()[i], (28, 28)) \n",
    "\t\ta[1][i].imshow(img, cmap='gray') \n",
    "\t\ta[1][i].set_xticks(())\n",
    "\t\ta[1][i].set_yticks(()) \n",
    "\tplt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.utils.data\n",
    "from torch.nn import functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 1) 하이퍼파라미터 설정\n",
    "batch_size = 128\n",
    "learning_rate = 1e-3\n",
    "num_epochs = 10\n",
    "z_dim = 20  # 잠재변수 차원\n",
    "\n",
    "# 2) MNIST 데이터셋 로드 & 전처리\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))  # MNIST 평균, 표준편차\n",
    "])\n",
    "\n",
    "# train_dataset = datasets.MNIST(\n",
    "#     root='data', train=True, download=True, transform=transform\n",
    "# )\n",
    "# test_dataset = datasets.MNIST(\n",
    "#     root='data', train=False, download=True, transform=transform\n",
    "# )\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('./data', train=True, download=True,\n",
    "                   transform=transforms.ToTensor()),\n",
    "    batch_size=128, shuffle=True, num_workers=4 ) #, pin_memory=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('./data', train=False, download=True,\n",
    "                   transform=transforms.ToTensor()),\n",
    "    batch_size=128, shuffle=False, num_workers=4)\n",
    "\n",
    "device = 'cpu' # torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim=784, hidden_dim=400, z_dim=20):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc_mu = nn.Linear(hidden_dim, z_dim)\n",
    "        self.fc_logvar = nn.Linear(hidden_dim, z_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: (batch_size, 784) 형태 (MNIST 이미지를 28x28 -> 784로 flatten)\n",
    "        return: (mu, log_var)\n",
    "        \"\"\"\n",
    "        h = torch.relu(self.fc1(x))\n",
    "        mu = self.fc_mu(h)\n",
    "        logvar = self.fc_logvar(h)\n",
    "        return mu, logvar\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, z_dim=20, hidden_dim=400, output_dim=784):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(z_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, z):\n",
    "        \"\"\"\n",
    "        z: (batch_size, z_dim) 형태\n",
    "        return: (batch_size, 784)\n",
    "        \"\"\"\n",
    "        h = torch.relu(self.fc1(z))\n",
    "        x_recon = torch.sigmoid(self.fc2(h))  # 픽셀값 0~1 범위로\n",
    "        return x_recon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, input_dim=784, hidden_dim=400, z_dim=20):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(input_dim, hidden_dim, z_dim)\n",
    "        self.decoder = Decoder(z_dim, hidden_dim, input_dim)\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        \"\"\"\n",
    "        Reparameterization Trick:\n",
    "        z = mu + sigma * eps,\n",
    "        where eps ~ N(0, I)\n",
    "        \"\"\"\n",
    "        std = torch.exp(0.5 * logvar)   # logvar = log(sigma^2)\n",
    "        eps = torch.randn_like(std)     # std와 같은 shape의 표준정규 샘플\n",
    "        return mu + eps * std\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: (batch_size, 784)\n",
    "        return: x_recon, mu, logvar\n",
    "        \"\"\"\n",
    "        mu, logvar = self.encoder(x)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        x_recon = self.decoder(z)\n",
    "        return x_recon, mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae_loss_function(x_recon, x, mu, logvar):\n",
    "    \"\"\"\n",
    "    x_recon: Decoder가 출력한 복원 이미지 (batch_size, 784)\n",
    "    x: 실제 입력 이미지 (batch_size, 784)\n",
    "    mu, logvar: Encoder에서 나온 z 분포 파라미터\n",
    "    \"\"\"\n",
    "    # 1) Reconstruction Loss\n",
    "    #   - x_recon은 0~1 범위의 확률처럼 해석 가능\n",
    "    #   - x는 (0~1 범위로 정규화된) 실제 픽셀값\n",
    "    recon_loss = F.binary_cross_entropy(\n",
    "        x_recon, x, reduction='sum')\n",
    "\n",
    "    # 2) KL Divergence: D_KL(q(z|x) || p(z))\n",
    "    #    (정규분포 p(z)=N(0,I)로 가정)\n",
    "    #    = 0.5 * sum(logvar.exp() + mu^2 - 1 - logvar)\n",
    "    kl_div = - 0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "\n",
    "    # 최종 loss = 재구성 오차 + KL\n",
    "    return recon_loss + kl_div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 165.5688\n",
      "Epoch [2/10], Loss: 121.8217\n",
      "Epoch [3/10], Loss: 114.8171\n",
      "Epoch [4/10], Loss: 111.9456\n",
      "Epoch [5/10], Loss: 110.1628\n",
      "Epoch [6/10], Loss: 108.9251\n",
      "Epoch [7/10], Loss: 108.0420\n",
      "Epoch [8/10], Loss: 107.3755\n",
      "Epoch [9/10], Loss: 106.7966\n",
      "Epoch [10/10], Loss: 106.3313\n"
     ]
    }
   ],
   "source": [
    "model = VAE(input_dim=784, hidden_dim=400, z_dim=z_dim).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "model.train()  # 학습 모드\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = 0.0\n",
    "    for idx, (x_batch, _) in enumerate(train_loader):\n",
    "        # 1) 데이터 준비\n",
    "        x_batch = x_batch.view(-1, 784).to(device)  # (batch_size, 784)\n",
    "        optimizer.zero_grad()\n",
    "        # 2) 순전파 (Forward)\n",
    "        x_recon, mu, logvar = model(x_batch)\n",
    "        # 3) 손실 계산 (ELBO의 음수 방향)\n",
    "        loss = vae_loss_function(x_recon, x_batch, mu, logvar)\n",
    "        # 4) 역전파 및 최적화\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "\n",
    "    # 배치 평균 또는 전체 샘플 수로 나눈 값으로 스케일 조정\n",
    "    avg_loss = train_loss / len(train_loader.dataset)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(epoch):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for idx, (data, _) in enumerate(test_loader):\n",
    "            data = data.to(device)\n",
    "            recon, mu, log_var = model(data)\n",
    "            test_loss += vae_loss_function(recon, data, mu, log_var).item()\n",
    "            if idx == 0:\n",
    "                n = min(data.size(0), 10)\n",
    "                comparison = torch.cat([data[:n],\n",
    "                                        recon.view(-1, 1, 28, 28)[:n]])\n",
    "                save_image(comparison.cpu(),\n",
    "                           './results/epoch_' + str(epoch) + '.png', nrow=n)\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('====> Test set loss: {:.4f}'.format(test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sim-0TBU-pA2-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
