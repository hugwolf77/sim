---
categories: 글쓰기
title: 5.2. VAR 분석 과정
created: 2025-02-14
tags:
  - SVU
  - seminar
  - timeseries
  - forecasting
  - VectorAR
  - 교재
  - 수업
  - 시계열
---
---
#### *VAR 분석 과정*
---

### 1) 시계열이 정상시계열(stationary series)인가의 여부를 확인

```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from statsmodels.tsa.stattools import adfuller, kpss

# 샘플 데이터 생성 (정상성을 갖는 시계열 데이터)
np.random.seed(0)
data = np.random.randn(100)
df = pd.DataFrame(data, columns=['data'])

# 1. 시각적 검정
plt.plot(df['data'])
plt.title('시계열 데이터')
plt.xlabel('시간')
plt.ylabel('값')
plt.show()

# 2. 통계적 검정 (ADF 검정)
adf_result = adfuller(df['data'])
print('ADF 검정 결과:')
print('ADF 통계량:', adf_result[0])
print('p-value:', adf_result[1])

# 3. 통계적 검정 (KPSS 검정)
kpss_result = kpss(df['data'])
print('KPSS 검정 결과:')
print('KPSS 통계량:', kpss_result[0])
print('p-value:', kpss_result[1])
```

### 2) 각 시계열이 비정상인 경우 시계열사이에 공적분(cointegration)관계가 있는지 여부를 확인
```python
from statsmodels.tsa.verctor_ar.vecm import coint_johnsen
result1 = coint_johansen(data,ar1,ar2)
from statsmodels.tsa.stattools import coint
coint(ar1, ar2)

# 공적분 벡터
result1.cvm # 임계값
result1.lr1 # 고유값
result1.trace_stat # trace 통계량
result1.evec # 공적분 vector
```

```python
import pandas as pd
import numpy as np
from statsmodels.tsa.api import VAR
from statsmodels.tsa.stattools import coint_johansen

# 샘플 데이터 생성 (3개의 시계열 데이터)
np.random.seed(0)
data = np.random.randn(100, 3)
df = pd.DataFrame(data, columns=['y1', 'y2', 'y3'])

# VAR 모델 적합 (lag order 결정을 위해)
model = VAR(df)
results = model.fit(maxlags=5) # 최대 5 lag까지 시도

# 요한슨 공적분 검정 수행
r = coint_johansen(df, det_order=results.k_ar, method='trace')

# 결과 해석
print(r.cvm) # 임계값
print(r.lr1) # 고유값
print(r.trace_stat) # trace 통계량

# 공적분 벡터 확인
print(r.evec)
```


### 3) 시계열사이에 공적분관계가 없을 경우 시계열을 차분(differencing)하여 정상 계열로 만듬

3-1) 두 시계열 사이에 공적분관계가 있을 경우에는 두 시계열의 차분 시 계열을 직접적으로 사용할 수 없음. => 과잉차분(overdifferencing)되어 미래 정보가 사라짐. 
3-2) 차분 시계열을 직접적으로 이용하지 않고 오차수정모형(error correction model; ECM)을 이용하여 분석
3-2) 또는 공적분벡터를 VAR 모델의 외생변수로 입력.

```python
import pandas as pd 
import numpy as np 
from statsmodels.tsa.api import VAR 
from statsmodels.tsa.vector_ar.vecm import VECM 

# 샘플 데이터 생성 (3개의 시계열 데이터) 
np.random.seed(0) 
data = np.random.randn(100, 3) 
df = pd.DataFrame(data, columns=['y1', 'y2', 'y3']) 

# VAR 모델 적합 
model = VAR(df) 
results = model.fit(maxlags=5) 

# 공적분 검정 
from statsmodels.tsa.stattools import coint 
coint_result = coint(df['y1'], df['y2']) 
# VECM 모델 적합 (공적분 관계가 존재한다고 가정) 
if coint_result[1] < 0.05: # 유의수준 5% 
	vecm = VECM(df, k_ar=results.k_ar, coint_rank=1) # 공적분 벡터 1개 
	vecm_results = vecm.fit() 
	print(vecm_results.summary()) 
else: print("공적분 관계가 존재하지 않습니다.")

```

### 4) 그랜저 인과관계검정(Granger Causality Test) 실시하여 사용한 변수의 설명력이 있는지 판단.
```python
import pandas as pd
import numpy as np
from statsmodels.tsa.stattools import grangercausalitytests

# 샘플 데이터 생성 (2개의 시계열 데이터)
np.random.seed(0)
data = np.random.randn(100, 2)
df = pd.DataFrame(data, columns=['y1', 'y2'])

# 그랜저 인과관계 검정 수행
maxlag = 4 # 최대 lag order
result = grangercausalitytests(df[['y1', 'y2']], maxlag=maxlag, verbose=True)

# 결과 해석
print(result)
```

- p-value가 유의수준(일반적으로 0.05)보다 작으면 귀무가설을 기각하고, 두 시계열 사이에 그랜저 인과관계가 존재한다고 판단
- **F-통계량**: F-통계량은 두 모델의 설명력을 비교하는 데 사용

### 5) VAR모형을 이용하여 시계열을 분석하고 모델의 적정성 판단 

```python
import pandas as pd
import numpy as np
from statsmodels.tsa.api import VAR
from statsmodels.tsa.stattools import acf, pacf
from statsmodels.stats.diagnostic import acorr_ljungbox, het_breuschpagan, normality_normaltest

# 샘플 데이터 생성 (2개의 시계열 데이터)
np.random.seed(0)
data = np.random.randn(100, 2)
df = pd.DataFrame(data, columns=['y1', 'y2'])

# VR 모형 적합
model = VAR(df)
results = model.fit(maxlags=5)

# 1. 잔차 분석
residuals = results.resid

# 잔차의 정상성 검정
acf_values = acf(residuals, nlags=20)
pacf_values = pacf(residuals, nlags=20)
ljungbox_result = acorr_ljungbox(residuals, lags=[10], return_df=True)

# 잔차의 정규성 검정
normaltest_result = normality_normaltest(residuals)

# 잔차의 이분산성 검정
breuschpagan_result = het_breuschpagan(residuals, exog_het=None)

# 2. 모형 안정성 검정
eigenvalues = results.roots

# 3. 정보 기준
aic = results.aic
bic = results.bic

# 결과 출력
print("잔차 정상성 검정 (Ljung-Box 검정):", ljungbox_result)
print("잔차 정규성 검정:", normaltest_result)
print("잔차 이분산성 검정 (Breusch-Pagan 검정):", breuschpagan_result)
print("특성근:", eigenvalues)
print("AIC:", aic)
print("BIC:", bic)
```


### 6) 모형의 예측력에 대한 테스트

**1. MAE (Mean Absolute Error, 평균 절대 오차)**
- **정의**: 실제값과 예측값의 차이의 절대값 평균
- **특징**: 직관적인 해석이 가능하며, 이상치에 덜 민감함
- **계산식**: MAE = (1/n) * Σ|y_actual - y_predicted|

**2. MSE (Mean Squared Error, 평균 제곱 오차)**
- **정의**: 실제값과 예측값의 차이의 제곱 평균
- **특징**: MAE보다 이상치에 민감하며, 큰 오차에 penalty를 부여함
- **계산식**: MSE = (1/n) * Σ(y_actual - y_predicted)^2

**3. RMSE (Root Mean Squared Error, 제곱근 평균 제곱 오차)**
- **정의**: MSE의 제곱근
- **특징**: MSE와 유사하지만, 원래 데이터와 동일한 scale을 가짐
- **계산식**: RMSE = sqrt(MSE)

**4. MAPE (Mean Absolute Percentage Error, 평균 절대 백분율 오차)**
- **정의**: 실제값과 예측값의 차이의 절대값을 실제값으로 나눈 후 백분율로 표현한 평균
- **특징**: 실제값의 크기에 상대적인 오차를 나타내며, 0에 가까울수록 정확도가 높음
- **계산식**: MAPE = (1/n) * Σ(|y_actual - y_predicted| / y_actual) * 100

**5. SMAPE (Symmetric Mean Absolute Percentage Error, 대칭 평균 절대 백분율 오차)**
- **정의**: MAPE의 단점을 보완하기 위해 실제값과 예측값의 평균으로 나누어 계산
- **특징**: MAPE와 유사하지만, 실제값이 0에 가까운 경우에도 안정적인 결과를 제공함
- **계산식**: SMAPE = (1/n) * Σ(|y_actual - y_predicted| / ((|y_actual| + |y_predicted|) / 2)) * 100

```python
import numpy as np
from sklearn.metrics import mean_absolute_error, mean_squared_error

# 실제값 및 예측값 (예시)
y_actual = np.array([10, 12, 15, 13, 18])
y_predicted = np.array([9, 11, 14, 12, 17])

# MAE 계산
mae = mean_absolute_error(y_actual, y_predicted)
print("MAE:", mae)

# MSE 계산
mse = mean_squared_error(y_actual, y_predicted)
print("MSE:", mse)

# RMSE 계산
rmse = np.sqrt(mse)
print("RMSE:", rmse)

# MAPE 계산 (0으로 나누는 경우를 방지하기 위해 1e-8 추가)
mape = np.mean(np.abs((y_actual - y_predicted) / y_actual)) * 100
print("MAPE:", mape)

# SMAPE 계산 (0으로 나누는 경우를 방지하기 위해 1e-8 추가)
smape = np.mean(np.abs(y_actual - y_predicted) / ((np.abs(y_actual) + np.abs(y_predicted)) / 2)) * 100
print("SMAPE:", smape)
```


### 7) VAR모형을 이용한 내생변수간의 동태적효과를 보기 위하여 충격반응분석(impulse response analysis) 및 분산분해분석(variance decomposition analysis)을 실시 

**1. 충격 반응 분석 (Impulse Response Analysis)**
충격 반응 분석은 특정 변수에 충격(shock)이 발생했을 때 다른 변수들이 어떻게 반응하는지 분석하는 방법입니다. 이는 VAR 모형의 계수를 이용하여 각 변수의 충격이 다른 변수에 미치는 동태적 효과를 파악하는 데 사용됩니다.

**충격 반응 분석 과정:**
1. **VAR 모형 적합**: 시계열 데이터를 사용하여 VAR 모형을 적합합니다.
2. **충격 설정**: 특정 변수에 대한 충격(일반적으로 1 표준편차)을 설정합니다.
3. **반응 경로 계산**: 설정된 충격이 다른 변수들에 미치는 영향을 시간 흐름에 따라 계산합니다.
4. **그래프 시각화**: 계산된 반응 경로를 그래프로 시각화하여 충격의 효과를 분석합니다.

**2. 분산 분해 (Variance Decomposition)**
분산 분해는 각 변수의 변동성이 다른 변수들의 충격에 의해 얼마나 설명되는지 분석하는 방법입니다. 이는 각 변수의 예측 오차 분산을 다른 변수들의 충격으로 분해하여 변수 간의 상대적 중요도를 파악하는 데 사용됩니다.

**분산 분해 과정:**
1. **VAR 모형 적합**: 시계열 데이터를 사용하여 VAR 모형을 적합합니다.
2. **예측 오차 분산 계산**: 각 변수의 예측 오차 분산을 계산합니다.
3. **분산 분해**: 계산된 예측 오차 분산을 다른 변수들의 충격으로 분해합니다.
4. **결과 해석**: 각 변수의 변동성이 다른 변수들의 충격에 의해 얼마나 설명되는지 분석합니다.

**파이썬 예제:**

```Python
import pandas as pd
import numpy as np
from statsmodels.tsa.api import VAR

# 샘플 데이터 생성 (3개의 시계열 데이터)
np.random.seed(0)
data = np.random.randn(100, 3)
df = pd.DataFrame(data, columns=['y1', 'y2', 'y3'])

# VAR 모형 적합
model = VAR(df)
results = model.fit(maxlags=5)

# 충격 반응 분석
irf = results.irf(periods=20) # 20 시점까지의 충격 반응 계산
irf.plot(orth=False) # 그래프 시각화 (orth=False: 직교화되지 않은 충격 반응 함수)

# 분산 분해
fevd = results.fevd(periods=20) # 20 시점까지의 분산 분해
fevd.plot() # 그래프 시각화

# 결과 해석
print("충격 반응 분석 결과:")
print(irf)
print("분산 분해 결과:")
print(fevd)
```

1. **충격 반응 분석**: `results.irf()`를 사용하여 충격 반응 함수를 계산하고, `irf.plot()`을 사용하여 그래프를 시각화합니다. `orth=False`는 직교화되지 않은 충격 반응 함수를 나타냅니다.
2. **분산 분해**: `results.fevd()`를 사용하여 분산 분해를 계산하고, `fevd.plot()`을 사용하여 그래프를 시각화합니다.
3. **결과 해석**: 계산된 충격 반응 함수 및 분산 분해 결과를 출력하고, 그래프를 통해 시각적으로 분석합니다.

