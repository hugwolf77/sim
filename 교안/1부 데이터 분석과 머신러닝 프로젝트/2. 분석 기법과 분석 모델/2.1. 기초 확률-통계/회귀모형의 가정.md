---
categories: algorithm
title: 회귀모형의 가정
created: 2024-12-10
tags:
  - algorithm
  - regression
---
---
#### *회귀모형의 가정*
---
https://blog.naver.com/yonxman/220973487496
#### 1. 일반선형회귀(OLS)의 가정

- 1) 선형성 : 독립변수(feature)의 변화에 따라 종속변수도 일정 크기로 변화해야 한다.
- 2) 정규성 : 잔차항(오차항)이 정규분포를 따라야 한다.
- 3) 독립성 : 독립변수의 값이 서로 관련되지 않아야 한다.
- 4) 등분산성 : 그룹간의 분산이 유사해야 한다. 독립변수의 모든 값에 대한 오차들의 분산은 일정해야 한다.
- 5) 다중공선성 : 다중회귀 분석 시 두 개 이상의 독립변수 간에 강한 상관관계가 있어서는 안된다

- example

```python

lmodel_mul = smf.ols(formula='sales ~ tv + radio',data=advdf).fit()
print(lmodel_mul.summary())

#예측 : 새로운 tv radio 값으로 sales를 추정
x_new2 = pd.DataFrame({'tv':[110,220,500],'radio':[10,30,60]})
pred_new2 = lmodel_mul.predict(x_new2)
print('추정값 : \n',pred_new2.values) #sales = [9.83 18.62 37.07]

```

- 선형성
	: 잔차와 추세선이 일정하지 않음.
```python

fitted = lmodel_mul.predict(advdf.iloc[:,0:2])
residual = advdf['sales'] - fitted
print('실제값 : ',advdf['sales'][:5].values)
print('예측값 : ',fitted[:5].values)
print('잔차값 : ',residual[:5].values)

import seaborn as sns
sns.regplot(x=fitted,y=residual,lowess = True,line_kws={'color':'red'}) #추세선
plt.plot([fitted.min(),fitted.max()],[0,0],'--',color='grey') #기준선
plt.show()

```

- 정규성
	:  shapiro test : 0.05 이하여야 함.
```python

sns.scatterplot(x=x,y=y)
plt.plot([-3,3],[-3,3],'--',color='grey')
plt.show()

# 잔차의 정규성. 
print('shapiro test : ',scipy.stats.shapiro(residual).pvalue) 
```
 
- 독립성
	: Durbin-Watso test - 회귀 모델의 잔차가 자기 상관관계 (0~2 양의 자기 상관관계, 2~4 음의 자기 상관관계)
```python

sns.regplot(x=fitted,y=np.sqrt(np.abs(sr)),lowess = True,line_kws={'color':'red'})
plt.show()
```

- 다중공선성
```python
from statsmodels.stats.outliers_influence import variance_inflation_factor
print(variance_inflation_factor(advdf.values,1)) #tv = 12.57  (다중공선성의심)
print(variance_inflation_factor(advdf.values,2)) #radio = 3.15
```
`VIF` : 분산 팽창 인수. 이 값은 다중회귀분석에서 독립변수가  
다중 공산성(Multicollnearity)의 문제를 갖고 있는지 판단하는 기준이며,  
주로 10보다 크면 그 독립변수는 다중공산성이 있다고 말한다.

- Cook's distance : outlier define index
```python
from statsmodels.stats.outliers_influence import OLSInfluence
cd , _ = OLSInfluence(lmodel_mul).cooks_distance 
print(cd.sort_values(ascending = False).head())
```
: OLSInfluence(lmodel_mul).cooks_distance  극단값을 확인할 수 있는 지표를 반환함

```python
import statsmodels.api as sm
sm.graphics.influence_plot(lmodel_mul,criterion='cooks')
plt.show()

print(advdf.iloc[[130,5,35,178,126]]) # 제거 대상 행 확인
```

#### 1-1. 회귀모형의 Classical Assumption

1) 총속변수와 독립변수 간 선형관계가 존재할 것
2) 독립변수와 오차항(error term) 간 상관관계가 없을 것.
3) 오차항의 기대값은 '0'
4) 오차항의 분산은 모든 관찰치에서 일정할 것 - '이분산성(Heteroskedasticity)'
5) 오차항 간 상관관계가 없을 것. - '계열 상관성(Serial Correlation)'
6) 독립변수간 상관관계가 없을 것.  - '다중공성선(Multicolinearity)'
7)  오차항은 정규분포할 것.


#### 2. #이분산성(Heteroskedasticity)

- 회귀모델에서의 오차항의 분산이 상수로 일정한 가정(조건)을 수식으로 나타내면 다음과 같다.

$$
\begin{align}
	var(\epsilon_{i})
	&=E[(\epsilon_{i}-E(\epsilon_{i}))^{2}] \\
	&=E(\epsilon_{i}^{2})=\sigma_{\epsilon}^{2}
\end{align}
$$
- 오차항의 분산이 모든 관찰값과 예측값 사이에서 동일한 상수(constant)를 의미.
- 그러나 실제는 오차항의 분산이 관찰값에 따라서 달라짐.
$$
\begin{align}
	E(\epsilon_{i}^{2})=\sigma_{i}^{2}
\end{align}
$$
1) 무조건부(unconditional) 이분산성 : 오차항의 분산이 독립변수 관찰값과 상관이 없는 경우.
2) 조건부(conditional) 이분산성 : 오차항의 분산과 독립변수가 일정한 상관관계를 보이는 경우

- 조건부 이분산성의 경우, 추정 회귀계수 유의성의 신뢰성에 심각한 오류 발생 가능성 높음.

![[heteroscedasticity.jpg]]
[Reference : Regression Modelling for Biostatistics 1](https://bookdown.org/stephane_heritier/RM1TEST/002-checking_assumptions.html)

3) 조건부 이분산성이 회귀분석에 미치는 영향
	- 회귀추정으로 산출된 표준오차(standard error)의 신뢰성 감소
	- 추정 (선형모델의) 회귀계수에 영향을 미치지 않는기 때문에 불편 추정량은 만족할 수 있다.
	- 표준오차가 과소계상될 경우, 추정 회귀계수의  통계량(T-value)이 과대평가되어 귀무가설을 기각하는 오류 발생 (1종-오류 : $\alpha error$)
	- F검정의 신뢰성 감소

4) 오차항의 변동성의 표준편차의 범위를 검증 - 브루쉬-페이건 검정법(Breush-Pagan test: BP test) 

$$
\begin{align}
	\epsilon_{i}^{2}=\gamma_{0}+\gamma_{1}x_{1i}+\gamma_{2}x_{2i}+\cdots+\gamma_{k}x_{ki}+u_{i}\ \ \ i=1,2,\cdots,n
\end{align}
$$

: 추정회귀모델의 추정 오차항의 제곱을 종속변수로 기존 추정회귀식에 사용된 독립(설명)변수와 보조 회귀모형(auxiliary regression) 이후 F-test 실시. 귀무가설을 기각된다면 종속변수(오차항)과 독립변수 간에 통계적 유의성이 있다는 의미로 이분산성을 의심할 수 있다. 추가로 Chi-Square 검정을 통해 이분산성 존재유무 확인

$$
\begin{align}
	BP\ chi-square\ test = n \times R^{2}_{auxiliary\ regression}
\end{align}
$$
