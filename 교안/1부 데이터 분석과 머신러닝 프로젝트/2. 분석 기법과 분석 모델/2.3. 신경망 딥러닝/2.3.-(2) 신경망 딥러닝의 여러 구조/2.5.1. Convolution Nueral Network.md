---
categories: 글쓰기
title: 2.5.1. Convolution Nueral Network
created: 2025-04-13
tags:
  - 수업
  - 교재
  - CNN-
---
---
#### *2.5.1 CNN*
---

---
## 1. Convolution NN
---
##### Convolution
- 하나의 함수와 또 다른 함수를 반전 이동한 값을 곱한 다음, 구간에 대해 적분하여 새로운 함수를 구하는 수학 연산자.

- convolution
$$
\begin{align}
	&(f*g)(t) \quad= \quad \int_{-\infty}^{\infty}\ \ f(\tau)g(t-\tau)d\tau \\ \\
\end{align}
$$

- Closs-collelation
- : 두 함수가 서로 얼마나 **유사**한지, 그리고 시간 축에서 얼마나 **떨어져** 있는지 (시간 지연)를 측정
$$
\begin{align}
	&(f*g)(t) \quad= \quad \int_{-\infty}^{\infty}\ \ f(\tau)g(t+\tau)d\tau \\ \\
	&(f*g)(t) \quad= \quad \int_{-\infty}^{\infty}\ \ f(t- \tau)g(\tau)d\tau \\ \\
\end{align}
$$

- 수학적으로는 컨벌루션은 함수 g를 **시간 역전 (g(−τ))** 시킨 후 슬라이딩하는 반면, 크로스코릴레이션은 시간 역전 없이 **그대로 (g(τ) 또는 g(t+τ))** 슬라이딩한다는 것

![[convolution2_20240326142734.png|500]]

#### Convolution NN
![[AlexNet.png]]
(출처) 출처:ImageNet Classification with Deep Convolutional Neural Networks

- 그러나 실제로 Convolution NN의 작동은 사실 Closs-collelation에 더 가깝다.

> - 단순, flattening 한 Neural Net 구조는  데이터의 구조적 (위치에 대한)정보는 의미가 없음. 층이 쌓일 수록 더욱 심해짐. 


- **입력 데이터 (Input Data):** 이미지와 같은 입력 데이터는 다차원 배열 (예: 흑백 이미지는 2D, 컬러 이미지는 3D)로 표현.
- **필터 (Filter 또는 Kernel):** 작은 크기의 가중치 행렬. CNN 학습 과정에서 이 필터의 가중치들이 학습.
- **Convolution 연산:** 필터가 입력 데이터 위를 특정 간격 (Stride)으로 슬라이딩하면서 겹치는 부분의 값들과 필터의 값들을 **element-wise 곱셈**한 후 모두 **합산**. 이 결과가 새로운 특징 맵 (Feature Map)의 한 요소가 됨.
- **특징 맵 (Feature Map):** Convolution 연산의 결과로 생성되는 출력. 각 특징 맵은 입력 데이터에서 특정 특징 (예: 모서리, 질감, 특정 패턴 등)이 감지된 정도를 나타냄.


```python
torch.nn.Conv2d(
		    in_channels, 
		    out_channels, 
		    kernel_size, 
		    stride=1, 
		    padding=0, 
		    dilation=1, 
		    groups=1, 
		    bias=True, 
		    padding_mode='zeros'
)
```

- pytorch  에서 입력되는 데이터 shape (batch_size, in_channel,)


#### Convolution NN과 MLP의 차이

1) 입력 데이터의 특성 차이(격자 형태 데이터 또는 입력 위치 정보가 중요한 데이터)
2) CNN은 데이터의 특징을 지역위치적 정보(**지역적인 특징(local features)**)와 함께 추출함. (반면 MLP는 입력되는 모든 특징들의 전체적인 관계를 학습)
3) 하나의 필터가 입력 데이터의 모든 위치에서 동일하게 적용되므로 학습해야 할 파라미터 수가 MLP에 비해 훨씬 적어 진다.
4) 풀링(Pooling) layer를 사용할 경우. 특징의 위치 변화에 강인해진다. (반면 MLP는 특징의 입력 위치 변화에 민감함.)
5) 여러 개의 필터를 사용하여 다양한 특징을 동시에 추출할 수 있음. 하나의 필터는 입력 데이터의 특정 패턴(예: 모서리, 선, 질감 등)에 반응하며, 필터들의 결과를 모와 **특징 맵(feature map)** 으로 출력.
6) 파라메터(가중치)에서 MLP 보다 적은 수의 가중치가 필터를 통해 학습되어 효율적이다.
7) 각 뉴런이 입력 데이터의 전체가 아닌 지역적인 일부에만 연결(**희소 연결(sparse connectivity)**)되므로 계산 효율성이 높다.

#### 간략한 구조
![[convolution1_20240326142734.png]]

- Local connectivity : 각 필터의 특정 위치 가중치는 재활용되면서 특정 요소만 학습
![[localconnectivity_20240326143816.png]]

#### stride
: 필터가 움직이는 간격

![[stride_20240326145606.png]]
#### Padding
: 입력 데이터가 반복적으로 CNN을 지날때 크기가 변화하는 것을 보정해주는 것
![[padding_20240326145650.png]]

#### Pooling
- 데이터의 크기를 조정하거나 특정 값으로 데이터를 mapping (CNN 같은 학습은 하지 않음: 즉, 가중치가 없음.) 

![[pooling_20240326145952.png]]

- 대표적으로  max pooling, average pooling 을 사용하여 크기를 줄여 주는 방법을 많이 사용.

https://pytorch.org/docs/stable/nn.html#convolution-layers

#### Dilation(팽창) : dilated convolution

- 필터의 가중치 간에 빈 가중치 공간을 주는 방법
- Dilated Convolution은 필터 내부에 zero padding을 추가하여 강제로수용하는 영역( receptive field)를 늘려주는 convolution
- receptive field이 넓을수록 이미지의 전체적인 특징, 문맥적(context)인 특징을 잡아내기 수월. 필터의 크기를 넓히게 되면 그만큼 가중치가 늘게 되고 overfitting이 발생.

https://justkode.kr/deep-learning/pytorch-cnn/


### Vision Deep Learning

##### 하나의 이미지(데이터) 안의 여러 객체 감지 문제

- 객체 감지(Object Detection) 분야의 핵심 이슈였음.
- 2단계 방법과 1단계 방법으로 나눠짐.

1) 2-단계(Two-Stage) 객체 감지기 방식
	- 1단계 작업 - **영역 제안(Region Proposal)** 
		: 객체가 있을 가능성이 높은 영역(Region of Interest, ROI)들을 이미지에서 추출. ( 전통적인 방식은 Selective Search, Edge Boxes 등이 사용 현재는 신경망 기반의 RPN(Region Proposal Network)이 주로 사용)
	- 2단계 작업 - **객체 분류 및 경계 상자 회귀(Object Classification and Bounding Box Regression)** 
		: 제안된 각 영역에 대해 해당 영역에 어떤 객체가 있는지 분류하고, 객체의 정확한 위치를 나타내는 경계 상자(bounding box)의 좌표를 예측.

	- R-CNN (Regions with CNN features) : Selective Search등 으로 ROI
		$\Longrightarrow$ Fast R-CNN : ROI pooling 기법 사용. 다양한 크기의 ROI 특징 맵을 고정된 크기로 출력. 연산속도 향상
		$\Longrightarrow$ Faster R-CNN : ROI 와 바운딩 박싱을 동시에 진행하는 RPN 신경망 도입 신경망으로 End to End 연결이 가능해짐.
		
> 	ROI Pooling (Region of Interest Pooling)
> 		1) 제안된 ROI의 좌표를 CNN의 특징 맵에 투영.
> 		2) 투영된 ROI 영역을 미리 정의된 고정된 크기의 격자(예: 7x7)로 나눔.
> 		3) 각 격자 셀 내의 특징 값에 대해 Max Pooling 등의 연산을 수행하여 하나의 대표 값을 추출.
> 		4) 이러한 과정을 통해 다양한 크기의 ROI로부터 항상 동일한 크기의 특징 벡터로 변환 가능. 이는 후속 가은 크기의 완전 연결 계층(Fully Connected Layer)의 입력로 사용할 수 잇게 함.
> 		5) **ROI Align**이라는 개선 기법이 Mask R-CNN에서 제안. 
> 	
> 	RPN(Region Proposal Network)

-
2) 1-단계(One-Stage) 객체 감지기
	: 영역 제안(ROI 제안)과 객체 분류/경계 상자 회귀(Bounding Box Regression)를 하나의 신경망에서 동시에 수행. 실시간(real-time) 객체 감지에 많이 도입됨. (응답속도 - latency 때문)
	
	- 이미지를 격자(grid) 형태로 나누고, 각 격자 셀에서 미리 정의된 다양한 크기와 비율의 앵커 박스(anchor boxes)를 생성.
	- 각 앵커 박스에 대해 객체의 존재 여부, 클래스 확률, 그리고 경계 상자 좌표의 오프셋(offset)을 직접 예측.

- **YOLO (You Only Look Once):** 이미지를 격자로 나누고 각 격자 셀에서 여러 개의 경계 상자와 클래스 확률을 동시에 예측. 이미지 전체를 한 번만 통과시키므로 매우 빠른 속도를 자랑. - 최근에는 YoLo-10 등이 나옴.
- **SSD (Single Shot MultiBox Detector):** 다양한 크기의 특징 맵에서 여러 개의 앵커 박스를 사용하여 다양한 크기의 객체를 감지하는 데 효과적. YOLO보다 작은 객체 감지 성능이 우수하다는 평가.
- **RetinaNet:** Focal Loss라는 새로운 손실 함수를 도입하여 1-단계 검출기의 정확도를 2-단계 검출기 수준으로 끌어올림.


#### 특이 구조 U-Net

![[U-Net.png]]


![[CNN-archi-history.png]]
![[CNN_Timeline.png]]
![[vision_models(2021).png]]



### 2021년 경부터는 **Vision Transformer (ViT)** 관련 연구가 주류를 이루고 있음.

---
https://medium.com/@ghonia/getting-started-with-vision-transformer-9ca06e56e139

![[Attention mechanism.png]]

![[image&Language.png]]



### 관련하여 알아두면 좋은 내용
##### GRAD-CAM
https://medium.com/@stepanulyanin/implementing-grad-cam-in-pytorch-ea0937c31e82
##### Style Transfer (Gram Matrix)
https://pytorch.org/tutorials/advanced/neural_style_tutorial.html

---

### NAS (Neural Architecture Search)

- 주어진 문제에 대해 최적의 성능을 내는 신경망 구조(architecture)를 자동으로 탐색하는 기술 
- 딥러닝 모델의 구조를 설계하는 것은 전통적으로 많은 경험과 전문 지식을 요구하는 수동적인 작업이었지만, NAS는 이 과정을 자동화하여 효율적이고 성능이 뛰어난 모델을 발견하는 것을 목표로 함.

- Efficient-Net의 핵심 아이디어와 초기 모델(EfficientNet-B0)의 아키텍처는 NAS 기술을 활용하여 설계
- YoLo-NAS https://docs.ultralytics.com/ko/models/yolo-nas/

##### 주요 개념

1) **탐색 공간 (Search Space):** 
	- NAS 알고리즘이 탐색할 수 있는 신경망 구조의 범위와 가능성을 정의. 
	- 레이어의 종류 (convolutional, pooling, fully connected 등), 필터 크기, 스트라이드, 활성화 함수, 레이어 연결 방식 등 다양한 설계 요소들을 포함
	- 탐색 공간을 어떻게 정의하느냐에 따라 NAS의 효율성과 탐색 가능한 최적 구조가 크게 달라짐.
    
2) **탐색 전략 (Search Strategy):** 
	- 정의된 탐색 공간 내에서 최적의 신경망 구조를 효율적으로 찾는 방법을 결정. 
        - **강화 학습 (Reinforcement Learning):** 신경망 구조를 생성하는 컨트롤러(Agent)를 학습시켜, 검증 데이터셋에서의 성능을 보상(Reward)으로 사용하여 더 나은 구조를 탐색하도록 유도.
	    - **진화 알고리즘 (Evolutionary Algorithms):** 초기 신경망 구조 집단을 생성하고, 성능이 좋은 구조를 선택하여 교배(crossover) 및 변이(mutation)를 통해 점진적으로 더 나은 구조를 탐색.
	    - **기울기 기반 방법 (Gradient-based Methods):** 신경망 구조 자체를 학습 가능한 파라미터로 간주하고, 검증 손실에 대한 기울기를 계산하여 더 나은 구조로 업데이트. 이는 탐색 과정을 훨씬 효율적으로 만들 수 있지만, 탐색 공간의 연속적인 완화(relaxation)가 필요.
	- 
3) **성능 평가 전략 (Performance Estimation Strategy):** 
	- 탐색된 신경망 구조의 성능을 추정하는 방법. 모든 후보 구조를 처음부터 끝까지 학습시키고 평가하는 것은 계산 비용이 매우 많이 들기 때문에, 효율적인 성능 평가 전략이 중요
	    - **완전 학습 (Full Training):** 후보 구조를 처음부터 완전히 학습시킨 후 검증 데이터셋으로 성능을 평가. 가장 정확, 많은 비용.
	    - **부분 학습 (Partial Training):** 제한된 에포크 또는 작은 데이터셋으로 후보 구조를 학습시키고 성능을 예측.
	    - **가중치 공유 (Weight Sharing):** 여러 후보 구조가 공유하는 부분을 활용하여 학습 비용을 줄이고 성능을 추정.
---
### 양자화 (Quantization) Vs 지식 증류 (Knowledge Distillation)

1) 양자화 (Quantization)
	: 딥러닝 모델의 가중치(weights)와 활성화 값(activations)을 높은 정밀도의 부동 소수점 숫자(일반적으로 32비트 또는 16비트)에서 낮은 정밀도의 정수(일반적으로 8비트 또는 그 이하)로 변환하는 기술.

2) 지식 증류 (Knowledge Distillation)
	- 크고 복잡한 "선생님(Teacher)" 모델의 지식을 작고 가벼운 "학생(Student)" 모델로 이전(transfer)하는 머신러닝 기술.
	- 선생님 모델은 단순히 정답(hard label)뿐만 아니라, 각 클래스에 대한 확률 분포(soft probability)와 중간 레이어의 특징 표현 등 풍부한 정보를 학습.
	- 학생 모델이 이러한 선생님 모델의 "소프트 타겟(soft targets)"과 중간 표현을 모방하도록 학습시켜, 단순히 정답만을 학습하는 것보다 더 풍부한 지식을 습득하고 일반화 성능을 향상시키도록 유도

|특징|지식 증류 (Knowledge Distillation)|양자화 (Quantization)|
|:--|:--|:--|
|**주요 목표**|큰 모델의 지식을 작은 모델로 이전하여 성능을 유지하거나 향상시키면서 모델 크기 및 연산량 감소|모델의 가중치 및 활성화 값을 낮은 정밀도로 표현하여 모델 크기 감소, 연산 속도 향상, 에너지 소비 절감|
|**작동 방식**|선생님 모델의 소프트 타겟 및 중간 표현을 모방하도록 학생 모델 학습|부동 소수점 값을 낮은 비트 수의 정수 값으로 매핑|
|**모델 구조 변경**|일반적으로 학생 모델은 선생님 모델과 다른 (더 작은) 구조를 가짐|모델 구조는 그대로 유지, 데이터 표현 방식만 변경|
|**성능 영향**|학생 모델의 용량에 따라 성능 감소가 있을 수 있지만, 종종 성능 향상도 가능|정밀도 손실로 인해 성능 감소가 발생할 수 있음|
|**주요 장점**|모델 압축과 함께 성능 향상 가능, 더 나은 일반화 능력 학습 유도|높은 압축률 및 속도 향상, 특수 하드웨어 활용 용이성|
|**주요 단점**|선생님 모델 학습 필요, 학생 모델 구조 설계 필요|정밀도 손실 가능, 양자화 방식에 따른 성능 변화 큼|
|**비전 딥러닝 적용**|경량화된 고성능 이미지 분류, 객체 감지, 분할 모델 개발|모바일 및 임베디드 환경에서의 효율적인 모델 추론|
