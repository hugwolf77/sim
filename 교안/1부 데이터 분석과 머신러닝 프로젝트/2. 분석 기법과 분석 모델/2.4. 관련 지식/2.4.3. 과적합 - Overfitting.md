---
categories: 
title: 과적합 - Overfitting
created: 2025-03-22
tags:
---
---
#### 과적합 - Overfitting
---

### 편향-분산 트레이드오프

테스트 오류를 줄이기 위해 학습 오류를 증가시키는 것을 편향-분산 트레이드 오프라고 합니다. 편향-분산 트레이드오프는 머신 러닝에서 잘 알려진 문제입니다. 먼저 '편향'과 '분산'을 정의해야 합니다. 간단히 설명하면 다음과 같습니다.

- **편향**은 예측값과 실제값의 평균 차이를 측정합니다. 편향이 증가하면 학습 데이터 세트에 대한 모델의 예측 정확도가 떨어집니다. 편향이 높다는 것은 학습 오류가 높다는 것을 의미합니다.

- **분산**은 주어진 모델의 다양한 실현에 대한 예측 간의 차이를 측정합니다. 분산이 증가하면 보이지 않는 데이터에 대한 모델의 예측 정확도가 떨어집니다. 분산이 높다는 것은 테스트 및 유효성 검사 중 오류가 많다는 의미입니다.

편향과 분산은 각각 학습 세트와 테스트 세트에 대한 모델 정확도와 반비례합니다. 2 개발자는 모델 편향과 분산을 모두 줄이는 것을 목표로 합니다. 그러나 이 둘을 동시에 줄이는 것이 항상 가능한 것은 아니므로 정규화가 필요합니다. 정규화는 편향을 증가시키는 대신 모델 분산을 줄입니다.


##### 과소와 과대적합
![[overfitting.png]]


정규화는 편향을 높이고 분산을 줄임으로써 모델 과적합을 해결합니다. 과적합은 학습 데이터의 오류는 감소하는 반면 테스트 데이터의 오류는 감소를 멈추거나 증가하기 시작할 때 발생합니다.3 즉, 과적합은 편향이 낮고 분산이 높은 모델을 설명합니다. 그러나 정규화로 인해 편향이 너무 심해지면 모델이 과소적합하게 됩니다.


![[fitting_tradeOff.png|500]]



- 타당성

- 신뢰성