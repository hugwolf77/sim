---
categories: 글쓰기
title: 2.4.7. Data Balance
created: 2025-04-07
tags:
  - 교재
  - 수업
  - Data_Balance
---
---
#### *Data Balance*
---
#### 1. Data Imbalance 영향

- 데이터 분석에서 라벨 불균형(Label Imbalance)은 특정 클래스(라벨)의 데이터가 다른 클래스에 비해 현저히 적거나 많은 상태를 의미 한다. 이러한 불균형은 분석 결과에 심각한 영향을 미칠 수 있으며, 모델의 성능을 저하시키는 주요 원인 중 하나이다.

1) 소수 클래스에 대한 모델 성능 저하: 
	- 불균형한 데이터셋으로 학습된 모델은 다수 클래스에 편향되어 소수 클래스를 제대로 학습하지 못할 가능성 있다.
	- 결과적으로 소수 클래스에 대한 예측 성능(정밀도, 재현율, F1 점수 등)이 현저히 낮아질 수 있다.

2) 정확도(Accuracy)의 함정:
	- 불균형한 데이터셋에서 모델의 전체 정확도는 높게 나타날 수 있지만, 이는 모델이 단순히 다수 클래스를 항상 옳다고 예측하기 때문일 수 있음.
	
3) 일반화 성능 저하:
	- 모델이 다수 클래스에 과적합(Overfitting)될 가능성이 높아져 일반화 성능이 떨어질 수 있음.

#### 2. 접근 방법
![[Resample_under&over.png]]

1) 데이터 레벨 방법(Resampling):
    - **오버샘플링(Oversampling):** 소수 클래스의 데이터를 복제하거나 생성하여 데이터 수를 늘리는 방법. (e.g., SMOTE, ADASYN)
    - **언더샘플링(Undersampling):** 다수 클래스의 데이터를 무작위로 제거하여 데이터 수를 줄이는 방법.
	- **데이터 증강(Data Augmentation):** 소수 클래스의 데이터를 변형하거나 합성하여 새로운 데이터를 생성하는 방법. (이미지, 텍스트 등 특정 데이터 유형에 적용 가능)

> - 오버샘플링과 언더샘플링의 가장 쉬운 구현은 랜덤하게 sample을 복제하는 것이다. 그러나 이는 Label class 에 따른 feature의 특성을 왜곡할 수 있다.
> - 오히려 Lable class에 따른 feature의 유사 데이터를 생성하는 데이터 증강을 많이 사용하는 추세이나 역시 왜곡의 가능성은 남아 있다.

2) 알고리즘 레벨 방법:
    - **클래스 가중치 조정(Class Weighting):** 모델 학습 시 소수 클래스에 더 큰 가중치를 부여하여 소수 클래스에 대한 학습 중요도를 높이는 방법.
    - **앙상블 기법(Ensemble Methods):** 여러 개의 모델을 결합하여 예측 성능을 향상시키는 방법으로, 불균형 데이터에 강한 앙상블 모델 사용. (e.g., Balanced Random Forest, EasyEnsemble).
    - **비용 민감 학습(Cost-Sensitive Learning):** 오분류 비용을 클래스별로 다르게 설정하여 소수 클래스의 오분류에 더 큰 페널티를 부여하는 방식.

3) 평가 지표 조정:
    - 정확도 대신 정밀도, 재현율, F1 점수, AUC 등 불균형한 데이터셋에 더 적합한 평가 지표를 사용하여 모델 성능을 평가.

#### 3. Python [imblearn-learn](https://imbalanced-learn.org/stable/)을 이용한 Resampling 


- Random Under Sampling
```python
from imblearn.under_sampling import RandomUnderSampler
rus = RandomUnderSampler()
X_rus, y_rus = rus.fit_resample(X, Y)
```

- Under Sampling with Tomek links
	- 다수 클래스에서 k-nearest neighbors에 있는 샘플만 무작위로 선택하여 제거하는 방식에서 Label class 간의 L2-distance가 가장 가까운 데이터 쌍 (`Tomek links`) 를 제거하는 방식으로 margin 을 최대한 늘리는 방식으로 변경
```python
from imblearn.under_sampling import TomekLinks
tlk = tomekLinks(sampling_strategy='majority')
X_tl, y_tl = tlk.fit_resample(X,y)
```
![[TomekLinks.png]]

- Random Over Sampling
```python
from imblearn.over_sampling import RandomOverSampler
ros = RandomOverSampler()
X_ros, y_ros = ros.fit_resample(X, y)
```

- Over-sampling : SMOTE(Synthetic Minority Oversampling TEchnique)
	- 이미 존재하는 소수 Label class에 대한 합성 요소로 생성
		1) 무작위 K-NN(k-nearest neighbors) 간의 L2-distance를 계산.
		2) 거리를 0~1 의 랜덤 수로 곱해서 랜덤의 한 거리로 feature 생성 합성한 sample을 생성 추가
		3) 즉, 선택 sample 포인트와 K-NN sample 포인트 사이에 생성.
		4) 소수 Label class 의 비율이 충족될 때까지 반복.
![[SMOTE.png]]
```python
from imblearn.over_sampling import SMOTE
smote = SMOTE(sampling_strategy='minority')
X_sm, Y_sm = smote.fit_resample(X,y)
```

- SMOTE and Tomek-Links
```python
from imblearn.combine import SMOTETomek
smt = SMOTETomek(smapling_stratagy='auto')
X_smt, Y_smt = smt.fit_resample(X,y)
```

#### 3. Python scikit-learn을 이용한 Resampling example

- Create imbalanceed data 
```python
import numpy as np
from sklearn.datasets import load_breast_cancer
from sklearn.utils import resample

# Load the breast cancer dataset
data = load_breast_cancer()
X = data.data
y = data.target

# Separate the dataset into benign and malignant
X_benign = X[y == 1]
X_malignant = X[y == 0]

# Downsample the malignant class to have only 30 instances
X_malignant_downsampled = resample(X_malignant, n_samples=30, random_state=42)

# Combine the downsampled malignant class with the benign class
X_imbalanced = np.vstack((X_benign, X_malignant_downsampled))
y_imbalanced = np.hstack((np.ones(X_benign.shape[0]), np.zeros(X_malignant_downsampled.shape[0])))

# Verify the counts of each class
benign_count = np.sum(y_imbalanced == 1)
malignant_count = np.sum(y_imbalanced == 0)
```

- Resample method for Oversampling or Upsampling Minority Class
```python
import numpy as np
from sklearn.utils import resample

# Create oversampled training data set for minority class

X_oversampled, y_oversampled = resample(
						X_imbalanced[y_imbalanced == 0],
						y_imbalanced[y_imbalanced == 0],replace=True,
						n_samples=X_imbalanced[y_imbalanced == 1].shape[0],
						random_state=123)

# Append the oversampled minority class to the imbalanced data and related labels
X_balanced = np.vstack((X_imbalanced[y_imbalanced == 1], X_oversampled))
y_balanced = np.hstack((y_imbalanced[y_imbalanced == 1], y_oversampled))
```

- Create a randomized search (RandomizedSearchCV) for model tuning
```python
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.pipeline import make_pipeline
from sklearn.metrics import accuracy_score
from sklearn.model_selection import RandomizedSearchCV
import scipy as sc

# Create training and test split using the balanced dataset
# created by oversampling

X_train, X_test, y_train, y_test = train_test_split(X_balanced, y_balanced, test_size=0.3, random_state=1, stratify=y_balanced)

# Create the pipeline
pipeline = make_pipeline(StandardScaler(), LogisticRegression(random_state=1))

# Create the randomized search estimator
param_distributions = [{'logisticregression__C': sc.stats.expon(scale=100)}]
rs = RandomizedSearchCV(estimator=pipeline, param_distributions = param_distributions, cv = 10, scoring = 'accuracy', refit = True, n_jobs = 1, random_state=1)

# Fit the model
rs.fit(X_train, y_train)

# Score the model
print('Best Score:', rs.best_score_, '\nBest Params:', rs.best_params_)
print('Test Accuracy: %0.3f' % rs.score(X_test, y_test))
```

- Resample method for Undersampling or Downsampling Majority Class
```python
# Downsample the majority class (class 1) to match the minority class count
X_majority_downsampled, y_majority_downsampled = resample(
X_imbalanced[y_imbalanced == 1], # Select only the majority class instances
y_imbalanced[y_imbalanced == 1], # Corresponding labels
replace=False, # No replacement, as this is downsampling
n_samples=minority_class_count, # The number of samples to match the minority class
random_state=123 # For reproducibility
)

# Combine the downsampled majority class with the original minority class
X_undersampled = np.vstack((X_imbalanced[y_imbalanced == 0], X_majority_downsampled))
y_undersampled = np.hstack((y_imbalanced[y_imbalanced == 0], y_majority_downsampled))

# Create training and test data split
X_train, X_test, y_train, y_test = train_test_split(X_balanced, y_balanced, test_size=0.3,random_state=1, stratify=y_balanced)

```

