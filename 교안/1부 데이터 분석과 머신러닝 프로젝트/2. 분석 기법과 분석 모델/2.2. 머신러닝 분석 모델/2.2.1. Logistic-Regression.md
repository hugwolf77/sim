---
categories: 
title: 2.2.1. Logistic-Regression
created: 2025-03-30
tags:
---
---
#### *2.2.1. Logistic-Regression*
---


![[로지스틱회귀 1.png]]

로지스틱 회귀의 목적은 일반적인 [회귀 분석](https://ko.wikipedia.org/wiki/%ED%9A%8C%EA%B7%80_%EB%B6%84%EC%84%9D "회귀 분석")의 목표와 동일하게 [종속 변수](https://ko.wikipedia.org/wiki/%EB%8F%85%EB%A6%BD_%EB%B3%80%EC%88%98%EC%99%80_%EC%A2%85%EC%86%8D_%EB%B3%80%EC%88%98 "독립 변수와 종속 변수")와 독립 변수간의 관계를 구체적인 함수로 나타내어 향후 예측 모델에 사용하는 것이다. 이는 독립 변수의 선형 결합으로 종속 변수를 설명한다는 관점에서는 [선형 회귀](https://ko.wikipedia.org/wiki/%EC%84%A0%ED%98%95_%ED%9A%8C%EA%B7%80 "선형 회귀") 분석과 유사하다. 하지만 로지스틱 회귀는 [선형 회귀](https://ko.wikipedia.org/wiki/%EC%84%A0%ED%98%95_%ED%9A%8C%EA%B7%80 "선형 회귀") 분석과는 다르게 종속 변수가 범주형 데이터를 대상으로 하며 입력 데이터가 주어졌을 때 해당 데이터의 결과가 특정 분류로 나뉘기 때문에 일종의 분류 ([classification](https://en.wikipedia.org/wiki/classification "en:classification")) 기법으로도 볼 수 있다.

- 로짓함수 로지스틱 함수

[logit function]![[sig&logit.png]]

[logistic function]![[logistic_func.png]]

- **로지스틱 모델 logistic regression**
___

- **odds** (오즈):  odds는 사건이 발생할 확률을 사건 발생하지 않을 확률로 나눈 비율
$$
odds= \frac{p}{1-p}
$$
- **logit**(로짓): $\pm\infty$ 범위에서 클래스에 속할 확률비율로 결정 
$$ 
logit(p) = log\frac{p}{1-p} = \hat\beta_{0}+\hat\beta_{1}x_{1}+\dots + \hat\beta_{d}x_{d}
$$
- **log odds**(로그 오즈): 선형모델의 변형 종속변수로 사용하여 확률에 관한 식으로 
$$
p=\frac{1}{1+e^{-(\hat\beta_{0}+\hat\beta_{1}x_{1}+\dots + \hat\beta_{d}x_{d})}}
$$


---
[scikit-learn-LogisticRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression)

###### [PipeLine](https://scikit-learn.org/stable/auto_examples/miscellaneous/plot_pipeline_display.html#sphx-glr-auto-examples-miscellaneous-plot-pipeline-display-py)
```python
from sklearn import set_config
from sklearn.linear_model import LogisticRegression
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler

steps = [
    ("preprocessing", StandardScaler()),
    ("classifier", LogisticRegression()),
]
pipe = Pipeline(steps)

set_config(display="diagram")
pipe  # click on the diagram below to see the details of each step
```


###### [Confusion Matrics](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.ConfusionMatrixDisplay.html)

###### [ROC display](https://scikit-learn.org/stable/auto_examples/model_selection/plot_det.html#sphx-glr-auto-examples-model-selection-plot-det-py)
```python
import matplotlib.pyplot as plt
from sklearn.metrics import DetCurveDisplay, RocCurveDisplay
from sklearn.metrics import ConfusionMatrixDisplay

fig, [ax_roc, ax_det] = plt.subplots(1, 2, figsize=(11, 5))

for name, clf in classifiers.items():
    clf.fit(X_train, y_train)
    RocCurveDisplay.from_estimator(clf, X_test, y_test, ax=ax_roc, name=name)
    DetCurveDisplay.from_estimator(clf, X_test, y_test, ax=ax_det, name=name)

ax_roc.set_title("Receiver Operating Characteristic (ROC) curves")
ax_det.set_title("Detection Error Tradeoff (DET) curves")

ax_roc.grid(linestyle="--")
ax_det.grid(linestyle="--")

plt.legend()
plt.show()
```

####### [Calibration Curve](https://scikit-learn.org/stable/auto_examples/calibration/plot_compare_calibration.html)
