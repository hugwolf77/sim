---
categories: 
title: 3.2. 머신러닝 분석 모형
created: 2024-10-29
tags:
---
---
#### *3.2. 머신러닝 분석 모형*
---
 
---
<font color="yellow"> 
	- 중간 입력 필요 분 //
</font>
	- 데이터의 입력 
		- 데이터의 분리
		- 데이터의 균형 - 데이터 증강, 데이터 감소, SMOTE
		- 데이터의 효율적 사용 - Cross-validation

![[split_data&Error.png]]
Fig. 1. Typical relationship between model error and complexity.
Copyright by Sara Wade
-
	- 군집분석
		- 계층적 분류
		 - 최근접 이웃
		 - GMM
		 - DBSCAN
		 - T-sne
- K-means
	 - 비지도학습으로 임의의 중점을 설정하고 그로부터 데이터 feature들의 평균거리를 계산하여 설정한 숫자 만큼의 중점에서 부터의 평균거리가 가장 작은 위치의 중점을 반복적으로 찾아가는 방법으로 중점을 찾고
	 - 그 중점에서 가까운 데이터들을 cluster member로 소속시키는 방법이다.
	 - 라벨이 필요 없고 직관적으로 이해가 쉬운 알고리즘이라는 장점이 있지만
	 - 중점의 수를 임의로 설정해야 한다는 점이 단점이다.
	 - K-NN 최근접 이웃법과의 차이는 K-NN은 분류(Classification)모델로 지도학습 기법이다.
		1) 군집의 개수(k) 설정하는 방법
			(1) Rule of thumb
			(2) Elbow Method
			(3) 정보 기준 접근법 (Information Criterion Approach)
		2) 초기 중점 설정하기
			(1) Randomly select
			(2) Manually assign
			(3) K-means++
		3) 데이터를 군집에 할당(배정)하기
		4) 중심점 재설정(갱신) 하기
		5) 데이터를 군집에 할당(배정)하기
	
	- 머신러닝 접근과 모델의 최적화
	- 과적합 방지과 일반화 (모델의 성능)
	- 모델의 규제 (Norm, L1, L2)

<font color="yellow"> 
	-  // 중간 입력 필요 분
</font>
---



---
### 2. 연관 분석 (장바구니 분석)
---
- '조건 $\longrightarrow$ 결과' 식으로 표현되는 유용한 패턴 (pattern)을 나타내는 연관 규칙(Association Rule) 발견하는 것.  베이즈 정리와 다르게 label의 카테고리가 없다는 것을 유의 해야 한다. 유사한 부분과 같은 의미인 부분을 생각해 보자
-  주요 기법 - FP-Growth 알고리즘, Apriori

#####  지지도 (support) 
- 동시 발생 확률  :

$$
	\begin{align}
		P(A\cap B) &= \frac{A와\ B가\ 함께\ 발생한\ 경우}{전체\ 발생\ 수} \\ \\
				   &= P(A) \times P(B) \quad (A와\ B가\ 독립인\ 경우)
		
	\end{align}
$$
#####  신뢰도 (confidence)
- 조건부 확률:  
$$
	\begin{align}
		\frac{P(A\cap B)}{P(A)} &= \frac{A와\ B가\ 함께\ 발생한\ 경우}{A를\ 포함하는\ 거래\ 수} \\ \\
								&= P(B|A)
	\end{align}
$$

#####  향상도 (lift)
- 두 상품의 독립 정도를 발생 확률 비율로 계산 (독립인 경우 동시 발생 확률을 두 확률의 곱으로 계산)
- 실제 관찰된 동시 발생 확률과 독립으로 계산한 경우의 비율 차이가 있으면 그만큼 상호 관계가 있다는 것
-  향상도가 = 1 이면 독립적 관계, 향상도가 > 1 이면 상호 상승관계, 향상도가 < 1 이면 상호 감쇄 관계

$$
	\begin{align}
		\frac{P(B|A)}{P(B)} &= \frac{P(A\cap B)}{P(A)P(B)} \\ \\
	\end{align}
$$
##### 최소 지지도 (minimum support)
- 불필요한 탐색 시간을 줄이기 위해서 최소한의 발생 확률을 분석자가 지정하는 파라메터


#### 1) 장점
	- 탐색적인 분석 기법으로 쉽게 이해가 되며, 분석방향이나 목적이 불분명해도 사용할 수 있다.
	- 구현이 쉽다.
#### 2) 단점
	- 데이터 세트가 커질 수록 반복적인 탐색으로 계산 비용이 크게 증가한다.
	- 후보 세트가 많아 질수록 메모리의 사용이 크게 증가한다.
	- 대규모 데이터 세트에서 실행시간이 길어진다.

- 일반적으로 1) 데이터 세트가 큰 경우 FP-Growth 를 사용한다 반면  Apriori 보다 해석이 복잡하다.

---
<font color="yellow"> 
	- 중간 입력 필요 분 //
</font>
- 유사성 
	- 데이터 거리
	- 분포간 거리
- 의사결정모델
- 의사결정 트리 모델 (Decision Tree)
	- Entropy
- 앙상블 모델
	- 랜덤 포레스트
	- XGBoost
- 나이브 베이지 의사결정
<font color="yellow"> 
	-  // 중간 입력 필요 분
</font>


---
### *3. 나이브 베이지안 알고리즘 (Naive Bayes Algorithm) 
---

##### 1)  확률(Probability)과 조건부확률(Conditional Probility)
---
- **확률(Probability)** : 어떠한 모집단(또는 현상)에서 모든 일어날 수 있는 샘플(사건-event들)의 경우의 수 (해당 모집단 데이터에서 발생할 수 있는 카테고리의 종류) 가운데 특정 샘플(사건-event)이 일어날 가능성을 뜻함.
 $$
\begin{align}
	&P(A)\ = \frac{n(A)}{n(S)}
\end{align}
$$

- 일반적으로 모집단 또는 특정 현상에서 발생할 모든 가능한 경우의 합의 확률로 1(100%)로 나타내며, 반대로 전혀 일어나지 않는 확률을 0(0%) 나타냄.
- 이와 연계해서 우리가 Logistic function, SoftMax function 에서 0~1 사이의 공간으로 모든 결과 값을 표현하기 이유를 알 수 있다.
- 이때 모든 경우의 수(총집합 S)라는 가정에 대하여 카테고리를 나눌 수 없는 경우를 여집합( $A^{c}$)으로 표현할 수 있다는 것을 염두해 두어야 함. 즉, 우리가 어떠한 현상에 대하여 모든 경우에 수를 알 수 없어도 표현상 카테고리를 분류 할 수 있다는 뜻이다. 더 나아가 이는 데이터 분석에서 결측값(missing data)을 더미(dummy) 데이터를 사용하여 구분하여 측정하고자 하는 데이터에 대한 여집합으로 표현하는 것과 연관해서 생각해 볼 수 있음.
 $$
\begin{align}
	&A^{c} = n(S)\ - n(A) 
\end{align}
$$

- 통계-분포와 연관성에 대해서 다시 생각해 볼 수 있음. 결국 샘플 데이터로부터 모집단의 특성값을 추정하는 통계는 그 분포를 통해서 확률 정보를 구할 수 있음.
- **조건부 확률(Conditional Probility)** : 특정한 샘플(사건-event)이 발생한 경우가 다른 샘플(사건-event)의 발생했다는 전제 하에 발생할 가능성.
$$
\begin{align}
	P(A|B)\ &=\ \frac{P(A\cap B)}{P(B)}\\ \\ 
	&=\ \frac{\frac{n(A\cap B)}{n(S)}}{\frac{n(B)}{n(S)}}\ =\ \frac{n(A \cap B)}{n(B)}
\end{align}
$$
![[Conditional_Probility_20241222010731.png]]
##### **2) 베이즈 정리(Baye's theorem)와 우도(Likelihood)**
---
- 베이즈 정리(Baye's theorem) : 어떠한 사건이 서로 **독립**으로 발생할 때 이전의 경험적 확률과 현재 확인한 정보를 바탕으로 사후 조건부 확률을 추정할 수 있기 때문.
- 즉 두 확률 변수의 사전 확률과 사후 확률 사이의 관계를 나타내는 정리. 즉, 역확률(inverse probability)문제를 구하기 위한 방법.
$$
\begin{align}
	&P(B|A)\ =\ \frac{P(A|B)P(B)}{P(A)}\ \propto\ P(B|A)\times\ P(B)\ =\ \frac{P(A \cap B)}{P(A)} \\ \\ 
	&P(A) : A의\ 사전 확률(evidence) : 일반적인\ A\ 사건이\ 발생할\ 확률로\ 일종의 관찰값에\ 대한\ 사전확률 \\
	&P(B) : B의\ 사전 확률(prior\ probability) : 일반적인\ B\ 사건이\ 발생할\ 확률 \\
	&P(A|B) :사건\ B가\ 주어졌을\ 때 \ A의 조건부 확률(likelihood) : 관찰\ 또는\ 수집,\ 실험에\ 의해\ 수집된\ 정보 \\
	&P(B|A) :사건\ A라는\ 증거에\ 대한\ 사후 확률(posterior\ probability) : 관찰\ 또는\ 수집,\ 실험에\ 의해\ 수집된\ 정보 \\
\end{align}
$$

$$
\begin{align}
	&P(\theta|data)\ =\ \frac{P(data|\theta)P(\theta)}{P(data)} \\ \\
	&P(\theta|data,M)\ =\ \frac{P(data|\theta,M)P(\theta,M)}{\int(P(data|\theta,M)\times P(\theta|M))d\theta} \\ \\
\end{align}
$$
- 일반적으로 evidence 다시  말해 관찰 값의 P(data)는 다음과 같이 구할 수 있음.
- 각 경우의 발생 확률(독립적으로 발생할 때) 모두 더해준다. 
- 또한 특정 경우를 분류하지 못하는 경우 우리는 $P(data|\theta)$를 알고 있고(데이터로 부터 관찰됨) 따라서 $P(data|-\theta)$ 즉, 여집합(또는 모든 관찰 결과의 확률의 가능도와 그 여집합)으로 알 수 있다.
- 이를 통해 전체 data에 대한 가능도(likelihood)의 총합을 구할 수 있고, 가능도의 총합이 P(data)가 된다. (이는 이산 독립을 전제 한다)
- 예시
> COVID-9의 발병률이 10%로 알려져 있음. 
> COVID-9에 실제로 걸렸을 때 검진 확률은 99% 임. 
> 실제로 걸리지 않았을 때 오검진될 확률이 1% 이라고 알려져 있음.

어떤 사람이 질병이 감염된 결과가 나왔을 때, 진짜 COVID-9 감염되었을 확률은?
	D: 검진
	발병 : $P(\theta)$ = 0.1, 발병일 때 검진 확률 $P(D|\theta)$ =0.99, 발병일 때 검진 안될 확률 $P(D|- \theta)$ =0.01 
	이때 $P(D)$ 는 $\sum_{\theta} P(D|\theta)P(\theta)=0.99\times 0.1 + 0.01\times 0.9 = 0.108$ 
	.
	이를 통해서 $P(\theta|D) = 0.1 \times \frac{0.99}{0.108} \approx 0.916$ 이 된다.

---
> [!NOTE] 베이즈 정리를 이용한 조건부 확률 계산의 쉬운 예시
> 조건 : 
> 	 - 박스 안에 A, B 두 개의 주머니가 존재 한다. 각 주머니에는 100개의 빨간 구슬과 파란 구슬 두 가지 종류가 들어 있다.
> 	- 박스 안에서 A, B  중 하나의 주머니를 선택할 때 A 주머니를 선택할 확률은 1/2 이다.
> 	- A 주머니에는 빨간 구슬이 60개 파란 구슬이 40개 들어 있다.
> 	- B 주머니에는 파란 구슬이 30개 파란 구슬이 70개 들어 있다.
> 
> 문제 : 
> 	- 박스 안에서 주머니에 손을 넣어서 하나의 구슬을 뽑았다. 이때 빨간 구슬이 나왔다면 이 구슬이 A 주머니에서 나왔을 확률을 구하라.
>
> 계산 :
> 	- 구하려는 조건부 확률을 표현하면 $P(A 주머니 | 빨간 구슬)$ 이 된다.
> 	- 이를 베이즈 정리로 바꿔서 보면 
> 	$$
> 		P(A\ 주머니 | 빨간\ 구슬)\ =\ \frac{P(빨간\ 구슬\ |\ A\ 주머니)\ P(A\ 주머니)}{P(빨간\ 구슬)}  
> 	$$
> 	- 먼저 $P(data)$ 즉, evidance 를 구하면  빨간 구슬이 나왔을 경우의 확률을 모두 더하면 된다. 따라서 A 주머니에서  빨간 구슬이 나왔을 확률 $p(A)\times P(빨간\ 구슬\ |\ A\ 주머니)\ = 1/2 \times 60/100$  과 B 주머니에서 빨간 구슬이 나왔을 확률 $p(B)\times P(빨간\ 구슬\ |\ B\ 주머니)\ = 1/2 \times 30/100$ 두 경우의 합이 된다.
> 	- 계산하면  $P(빨간\ 구슬)\ =\ (1/2 \times 60/100)\ +\ (1/2 \times 30/100)\ =\ 0.45$ 이다.
> 	- 따라서 베이즈 정리식에 이를 대입하면 
> 	$$
> 		\begin{align}
> 		P(A\ 주머니 | 빨간\ 구슬)\ &=\ \frac{P(빨간\ 구슬\ |\ A\ 주머니)\ P(A\ 주머니)}{P(빨간\ 구슬)} \\ &=\ \frac{(1/2 \times 60/100)\times 1/2}{0.45}\ \\ &=\ 0.3333\dots 
> 		\end{align} 
> 	$$
> 	- 우리가 박스 안에서 하나의 빨간 구슬을 뽑았을 때, 이 구슬이 A 주머니에서 나왔을 확률은 $33.333\dots \%$ 가 된다.



---


>[!NOTE]
> 분류(classification) 문제와 연계시켜 이해하면
> 사전확률, 민감도(재현율Recall), 오탐율(1종-오류)를 가지고 새로운 정밀도(Precision)을 구하는 문제임
![[bayesPbr_ConfusionM.png]]

- 조건부 확률에서 발생하는 인식의 오류를 조심해야 함.  쉬운 예로 교통사고 안전벨트 예가 있다. 교통사고로 사망한 사람의 30%가 안전벨트를 메지 않았다는 확률을 이라고 하면, 이를 잘못 오해하면 70%는 안전벨트를 메고도 사망한 것이 된다. 이는 전체 운전자 중 안전벨트를 하는 확률이라는 경우가 빠져 있는 것이다. 전제 사건을 기본 전체 확률로 가정하는 오류이다. 경우의 정보가 부족한 문제이다. 즉, 정확한 확률을 구하기 위해서는 안전벨트를 메는 일반적인 확률(안전벨트 사전확률)과  교통사고에 대한 확률(사망사고의 사전확률)에 대한 정보가 필요하다.
	[위키피디아 예시](https://namu.wiki/w/%EC%A1%B0%EA%B1%B4%EB%B6%80%ED%99%95%EB%A5%A0)
- 이러한 문제로 "몬티 홀 문제", "검사의 오류prosecutor's fallacy)"  등이 있다. 
- 이러한 조건부 확률 함정을 조심해야 하는 이유는 "베이즈 정리"는 전통적인 확률 추정에서는 모집단을 변하지 않는 현상값으로 규정하지만, "베이즈 관점"에서는 모집단을 미리 확정 짓지 않고 현재의 증거의 우도(likelihood)에 의해 규정하기기 때문에 오류에 빠지기 쉽기 때문이다. 

- [정보 엔트로피와 연계해서 생각해보자] : 조건부 엔트로피의 총합 => 그러나 만약 균등분포(독립적인 발생)의 확률이라면 각각의 확률 엔트로피의 합으로 계산 가능. 모든 확률의 동시 발생확률

$$
\begin{align}
	& P_{i}\ =\ 1/n \\ \\
	&S\ =\ -\sum_{i=1}^{n}{P_{i}lnP_{i}} = ln\ n 
\end{align}
$$
>[!Note]
>- **왜 로그를 사용할까요?**
>- **확률의 곱셈을 덧셈으로 변환:** 여러 사건이 동시에 발생할 확률은 개별 사건의 확률을 곱해야 합니다. 로그를 취하면 곱셈이 덧셈으로 바뀌어 계산이 간편해집니다.
>- **작은 값을 다루기 쉽게:** 확률은 0과 1 사이의 값을 가지므로, 매우 작은 값을 다룰 때 로그를 취하면 상대적으로 큰 값으로 변환되어 계산 오차를 줄일 수 있습니다.
>- **정보량의 가산성:** 서로 독립적인 두 사건에 대한 정보량은 각각의 정보량을 더한 것과 같습니다. 로그를 사용하면 이러한 가산성을 만족시킬 수 있습니다.


##### 3) Naive Bayes Classifier 
---

- 각 조건 변수가 발생할 경우에 대해서 발생 확률이 독립이라고 가정하면 독립된 사건에 대한 동시 발생확률은 단순한 곱으로 계산 할 수 있다.
- 현실에서는 이러한 조건 변수들이 완전히 독립이라고 보는 것은 순진한(Naive)한 생각이다. 그러나 이러한 가정으로 보아도 충분히 의미 있는 확률을 구할 수 있기 때문에 이러한 가정을 사용한다.
- (또는 독립이 되도록 변수를 통제할 수 있다면 유의미한 분석이 된다.)

 - 수학적 정의를  데이터에 대한 모델로 적용한다면
$$
\begin{align}
	&P(y|X)\ =\ \frac{P(X|y)\cdot P(y)}{P(X)} \\
	& X\ =\ (x_{1},x_{2},x_{3},\cdots,x_{n})
\end{align}
$$

 - y는 분류할 class 이다. X 는 입력 변수 (feature) 조건이 되고,  $p(y|X)$ y class가 X feature 에 대해서 발생할 확률이 된다.
$$
\begin{align}
	&P(y|x_{1},\cdots,x_{n})\ =\ \frac{P(x_{1}|y)P(x_{2}|y)\cdots P(x_{n}|y)\cdot P(y)}  {P(x_{1})P(x_{2})\cdots P(x_{n})} \\ \\
	& P(A,B) = P(A)P(B) \quad iid, A,B
\end{align}
$$
-  x 에 대한 일반화하면
$$
\begin{align}
	&P(y|x_{1},\cdots,x_{n})\ =\ \frac{P(y)\Pi_{i=1}^{n} P(x_{n}|y)}  {P(x_{1})P(x_{2})\cdots P(x_{n})} \\ \\
	& P(A,B) = P(A)P(B) \quad iid, A,B
\end{align}
$$
- x 데이터에 대한 관찰 값에 모든 확률에 대한 일반화로 보면
$$
\begin{align}
	& P(y|x_{1},\cdots,x_{n})\ \propto \ P(y)\Pi_{i=1}^{n} P(x_{n}|y)
\end{align}
$$
- 결국 예측하고자 하는  y class에 대해서 확률로

$$
\begin{align}
	& P(y|x_{1},\cdots,x_{n})\ argmax_{y} \ P(y)\Pi_{i=1}^{n} P(x_{n}|y) \\ \\
	& y =\ argmax_{y} \ P(y)\Pi_{i=1}^{n} P(x_{n}|y)
\end{align}
$$

- ex 01 : Weather & Play Dataset [example reference](https://www.javatpoint.com/machine-learning-naive-bayes-classifier)

| no  | Outlook  | Play |
| --- | -------- | ---- |
| 0   | Rainy    | Yes  |
| 1   | Sunny    | Yes  |
| 2   | Overcast | Yes  |
| 3   | Overcast | Yes  |
| 4   | Sunny    | No   |
| 5   | Rainy    | Yes  |
| 6   | Sunny    | Yes  |
| 7   | Overcast | Yes  |
| 8   | Rainy    | No   |
| 9   | Sunny    | No   |
| 10  | Sunny    | Yes  |
| 11  | Rainy    | No   |
| 12  | Overcast | Yes  |
| 13  | Overcast | Yes  |
- Frequency Table

| Weather  | Yes | No  |
| -------- | --- | --- |
| Overcast | 5   | 0   |
| Rainy    | 2   | 2   |
| Sunny    | 3   | 2   |
| Total    | 10  | 5   |

- Likelihood table 

| Weather  | Yes        | No        |           |
| -------- | ---------- | --------- | --------- |
| Overcast | 5          | 0         | 5/14=0.35 |
| Rainy    | 2          | 2         | 4/14=0.29 |
| Sunny    | 3          | 2         | 5/14=0.35 |
| All      | 10/14=0.71 | 4/14=0.29 |           |
|          |            |           |           |
P(Yes|Sunny) = P(Sunny|Yes)*P(Yes) / P(Sunny)
             = ( ( 3/10 ) x 0.71  ) / 0.35 = 0.60

P(No|Sunny) = P(Sunny|No)P(No) / P(Sunny)
             = ( ( 2/4 ) x 0.29  ) / 0.35 = 0.41


- ex 01 : Spam Mail  [example reference](https://medium.com/analytics-vidhya/na%C3%AFve-bayes-algorithm-5bf31e9032a2)
	+ Not Spam mail : 15
	+ Spam mail : 10
	+ below table show the frequency of each word had been recorded

| word       | Not Spam | Spam |
| ---------- | -------- | ---- |
| Dear       | 8        | 3    |
| Visit      | 2        | 6    |
| Invitation | 5        | 2    |
| Link       | 2        | 7    |
| Friend     | 6        | 1    |
| Hello      | 5        | 4    |
| Discount   | 0        | 8    |
| Money      | 1        | 7    |
| Click      | 2        | 9    |
| Dinner     | 3        | 0    |
| Total      | 34       | 47   |
- P(Dear|Not Spam) = 8/34
- P(Visit|Not Spam) = 2/34
- P(Dear|Spam) = 3/47
- P(Visit|Spam) = 6/47

- "Hello friend" ??
- "Hello friend" => "Hello" , "friend"  
	: Naive assume => *the features we use to predict the target are independent*

- P("Hello friend"|Not Spam) = P("Hello"|Not Spam) x P("friend"|Not Spam) 

- P(Not Spam|"Hello friend") = P("Hello"|Not Spam) x P("friend"|Not Spam) x P(Not Spam)
						 = (5/34 x 6/34) x 15/25 = 0.0155
- P(Spam|"Hello friend") = (4/47 x 1/47) x 10/25 = 0.00072 

##### Laplace smoothing

- 입력 조건 변수에 대한 경우의 수가 0인 경우가 있을 경우 확률 계산을 할 수 없게 된다.
- (여-집합으로 분류할 수 없는 별개의 입력 조건 변수)
- 이럴 경우 간단한 조작 트릭으로 문제를 해결 할 수 있다.

**Zero-Frequency Problem** : feature does not appear in the dataset, so that P is zero, hence all other probabilities will have no effect

- technique for smoothing categorical data

$$
\begin{align}
	&\hat\theta\ =\ \frac{x_{i}+\alpha}{N +\alpha d} \quad (i=1,\cdots,d) \\ \\
	& \alpha : smoothing parameter \\
	& x = (x_{1},\cdots,x_{d}): observation count \\
	& N : multinominal\ distribution\ trial\ count
	
\end{align}
$$
- Not smoothing :
	 P(Spam|"dear visit dinner money money money")
			= P("dear visit dinner money money money"|Spam) x P(Spam)
			= ( 3/47 x 6/47 x 0 x $(7/47)^{3}$ ) x 10/25 = 0 
- Laplace smoothing :
	 P(Spam|"dear visit dinner money money money")
			= P("dear visit dinner money money money"|Spam) x P(Spam)
			= ( $\frac{3+1}{47+10}$ x $\frac{6+1}{47+10}$ x $\frac{0+1}{47+10}$ x $(\frac{7+1}{47+10})^{3}$ ) x 10/25 = 4.18 x $10^{-7}$  = 1.672 x $10^{-7}$  

- 그러나 이러한 입력 조건의 경우의 수가 0 이 아니라 기존 학습 데이터 안에 측정 되지 않는 경우
- 또는 단위가 구분되는 (descreted) 한 데이터가 아니라 연속적인 (continued) 한 데이터인 경우에 대해서 확률 분포를 사용하여 접근 할 수 있다. 이는 다음의 가우시안 나이브 베이즈 분류기를 사용하는 이유이다.

##### 4) Gaussian Naive Bayes Classifier : GNB  Classifier
---
- 이는 입력 조건 변수의 데이터 샘플을 통해서 해당 조건의 변수에 대한 평균과 분산을 통해서 확률분포를 추정한다. 즉, 기존에 경우의 수를 계산하여 확률을 구했다면 이를 대신 정규분포 형태로 추정하여 계산한다.
- 이때 샘플 데이터에서 해당 조건 변수의 정규분포(가우시안 분포)를 추정하는 방법은 최대우도추정법(Maximum Likelihood Estimates: MLE [[2.2. 머신러닝 분석 모형#*6. 최대우도 (Maximum Likehood)*]])




- 또한 이런 경우 evidance를 구하는 것이 일반화되어 알려져 있다면 더욱 쉬워질 수도 있다.



---
### *3. 의사 결정 트리 모델  중요 개념*
___

##### 기본 개념

- 각 입력 feature 에 따른 종속 결과 값을 분리하는 과정을 모든 가능한 입력 feature의 조합에 따라 계층적 트리(tree) 구조로 분기를  만들어 가면서 분류 분석 또는 회귀분석을 진행하는 모델로
- 분기 이후 각 영역의 순도(homogeneity)가 증가하고 불순도(impurity)가 최대한 낮아지도록 학습. (Tree and Rule 구조)
- 분기 순간의 최선이라고 보이는 형태의 구조를 선택하기 때문에 탐욕적 알고리즘(greedy algorithm)이라고도 함.

- **Root Node** : 가장 최초의 분류 기준
- **Intermediate Node** :  중간 분류 기준
- **Terminal Node** (Leaf Node) : 갈라지지 않는 마지막 노드
 - **분기 기준** : 불순도 알고리즘을 통해 **Purity**(한 클래스만 존재 할수록 높음) **entropy** (무질서도 )를 계산하여 분기 

##### 불순도 알고리즘

1. Gini index
$$ Gini\ \ Index(A) =  1 - \sum_{i=1}^{C}P_{i}^{2} \ (A=사전\ 경우\ 수, C=발생\ 경우\ 수\ )$$ 
2. Entropy index
 $$ Entropy\ Index(A) =  - \sum_{i=1}^{C}P_{i}log_{2}(P_{i}) \ (A=사전\ 경우\ 수, C=발생\ 경우\ 수\ )$$
##### 정보 획득 Information gain
- 분기 이전의 불순도 계산과 분기 이후의 불순도의 차이를 정보 획득이라 표현
- 만약 Root Node 에서  불순도가 1 이 였다면 분기를 통해서 0.8인 상태로 바뀌었다면 정보를 0.2 의 정보를 획득한 것이다.
- 각 feature 에 따라서 Information gain을 계산하고 가장 순도가 높아지는 feature를 기준으로  분기 => 이를 하위 노드에서 더 이상 분기 하지 못할때 까지 반복
##### 가지치기 pruning
- Leaf Node 가 모두 최대 순도가 되게 분기하면 Full Tree가 된다. 이런 경우 각 feature 마다가 모두 반영되어 Overfitting이 발생하여 일반화된 예측이나 분류가 어렵다.
- 특정 분기 이하의 Tree 아래의 Node 분기를 진행하지 않게 하는 것 (자르는 것)
- 파라미터로 최대 깊이, 최대 leaf, Node 분할을 위한 초소 경우의 샘플 수 등을 정한다.
- 여러 분기 중 모델 적합도를 비용함수로 계산하여 모델을 선정한다.

 Err : validataion 에서의 오분류 또는 예측 오류 정도
 L : 모델의 복잡도, leaf node 의 수 등으로 모델의 크기와 복잡도
 $\alpha$ : Err 와 L의 결합 가중치 
 $$비용함수 = Err + \alpha \times L$$

##### 장점
- 수치형과 범주형 데이터 모두 사용가능
- 정규화하지 않는 원래  feature가 가진 scale을 사용할 수 있다,.
- feature 간의 중요도를 비교할 수 있다.



 - 정보학적으로는 Information gain(정보이득)이 높을 수록 희소성과 순도, 불확실성(구분)이 높다는 뜻이다. 

---
### 4. 분석 모델의 중첩과 부스팅 기법 : Random forest
___

##### 개념

- 여러 BASE 모델의 prediction의 결과를 통합하여 결과물의 성능을 높이는 기법이다.
- 하나의 모델의 성능이 낮더라도 (weak learner) 다른 방법론의 모델을 수개 겹치면 강한 성능의 모델 (strong learner)를 만들 수 있다.
- 이때 개별 BASE 모델은 독립적이어야 한다.

##### Voting
- 하드 보팅: 무조건 가장 많은 표를 획득한 결과
- 소프트 보팅: 예측한 확률을 합산하여 가장 높은 결과 결정
-  가중(weighting) 보팅: 모델  별로 별도의 가중치를 주어 투표

##### Bagging
- 하위 모델이 서로 다른 학습데이터를 사용
- 같은 크기의 다른 데이터를 만들기 위해서 복원 추출을 사용
- 각각의 개별 데이터 셋을 Bootstrap 이라 함.
- 결과를 집계(Aggregating)  분류 경우 최빈값, 회귀일 경우 평균 사용
- 비중복 샘플링 Pasting 

##### Stacking
- 하나 또는 수개의 모델의 결과 값을 최종 모델의 학습 데이터로 사용하는 예측 방법
- 예측에 실패한 부분 만큼 추가 가중치를 부여 하여 모델 학습 boosting

#### 랜덤 포레스트
- 앙상블 중 Bagging 방법의 확장
- Bagging과 무작위 feature 선정 활용하여 의사결정 트리를 구성하여 앙상블 실시


---
### *5. 의사 결정 트리 모델 실습 : XGBoost*
___

https://xgboost.readthedocs.io/en/stable/







---
### *6. 최대우도 (Maximum Likehood)*
---

##### 1) 최대우도 (Maximum Likehood)
---
#### **확률**

- 분포가 정해지고 → 정규분포
- 모수가 정해졌을 때 → 평균(μ)(μ) = 0, 분산(σ2)(σ2) = 1   (X∼Norm(0,1)X∼Norm(0,1))
- **관측치가** **나올 가능성** (ex. 2보다 작은 값이 나올 확률) → Pr(X≤2|X∼Norm(0,1))=0.97725Pr(X≤2|X∼Norm(0,1))=0.97725

#### **우도**

- 분포가 정해지고 → 정규분포
- 관측치가 주어졌을 때 → 100개의 샘플이 있다
- **모수가 나올 가능성** → **우도(Likelihood)**

-  최대우도법 (MLE)
**최대가능도방법** (最大可能度方法, : maximum likelihood method) 또는 **최대우도법**(最大尤度法)은 어떤 확률변수에서 [표집] 한 값들을 토대로 그 확률변수의 [모수]를 구하는 방법이다. 어떤 모수가 주어졌을 때, 원하는 값들이 나올 [가능도]를 최대로 만드는 모수를 선택하는 방법이다. [점추정] 방식에 속한다.

### Bayes' Theorem

$$
	\begin{align}
		P(A|B) &= \frac{P(B|A)P(A)}{P(B)} \propto \mathcal L(A|B)\ P(A) \\
	\end{align}
$$

- $\mathcal L$ 은 우도(Likelihood) 즉, 가능도를 의미한다.
- $P(B) = \int_{A} P(B|A)$   B에 대한 사전 확률로서 정규화 상수(Normalization Factor) 역할. 즉, 모든 A 조건에서의 B확률들을 합하여 추정


#### 2) Maximum Likelihood Estimation
---

출처: [공돌이의 수학정리노트](https://angeloyeo.github.io/2021/02/08/GMM_and_EM.html)
<center>
<img src="https://raw.githubusercontent.com/angeloyeo/angeloyeo.github.io/master/pics/2020-07-17-MLE/pic1.png" width =300 height=200>
</center>

- 우도 : 확률변수 $X$가 모수 $\theta$ 에 대한 확률분포 $P_{\theta}(X)$를 가지며, $X$가 특정한 값  $x$ 으로 표집되 었을 경우, $\theta$ 의 가능도 함수 $\mathcal L (\theta|x)$ 는 다음과 같이 정의 한다.

$$ \mathcal L (\theta|x) =  P(X=x|\theta)$$

- 만약에 $\theta$에 대해서 정규분포라고 가정할 수 있다면, $\theta = (\mu, \sigma)$  평균과 표준편차로 그 특성을 나타낼 수 있다. 이때 한 개의 데이터 $x_{n}$ 가 정규분포를 따를 확률은 해당 관찰 값을  해당 평균과 표준편차로 되어 있는 정규분포 식에 대입하는 것과 같다.

$$
	\begin{align}
		P(x_{n}|\theta) &= \frac{1}{\sqrt{2\pi\sigma}}exp \{-\frac{(x_{n}-\mu)^{2}}{2\sigma^{2}} \}
	\end{align}
$$
- 이후 모든 관찰 데이터를 독립이라고 가정하면 다음과 같이 우도(Likelihood: 가능도)를 계산할 수 있다.

$$
	\begin{align}
		\mathcal L (\theta) =  P(X|\theta) = \Pi_{n=1}^{N}p(x_{n}|\theta)
	\end{align}
$$

![[MaxLikehoood.png]]


 - MLE (Maximum Likelihood Estimation) 은 결국 이렇게 가능도를 계산하여 주어진 관찰 값을 통해서 가능도가 최대가 되는 분포를 찾는 것이 된다. (왜냐하면 가능도가 최대가 되는 정규분포가 해당 관찰 값들의 진짜 정규분포일 가능성이 높다는 뜻이기 때문이다.)

$$
\begin{align}
	&\square\ Maximum\ Likelihood\ Estimates:\ MLE \\ \\
	& \hat\mu_{ik}\ =\ \frac{1}{\sum_{j} \delta(Y^{j}=y_{k})}\sum_{j}X_{i}^{j}\delta(Y^{j}=y_{k}) \\ \\
	& \hat\sigma_{ik}\ =\ \frac{1}{\sum_{j} \delta(Y^{j}=y_{k})}\sum_{j}(X_{i}^{j}-\hat\mu_{ik})^{2}\delta(Y^{j}=y_{k}) \\ \\
	&i\ :\ i_{th}\ feature,\ \ k\ : k_{th}\ class,\ \ j\ :\ j_{th}\ training\ example,\ \ \delta\ :\ \delta(z)=1\ if\ z\ true\ else\ 0
\end{align}
$$

 - 딥러닝 시간의 그라디언트 디센팅을 생각해 보자 우리가 어떠한 최대값과 최소값이 되는 경우를 찾을 때 미분을 통해서 구하는 방법을 많이 사용함을 알고 있다.
- 이때 미분을 쉽게 구하기 위해서 log 형태로 우도식을 변형한다. 이 처럼 log 형태를 취하는 우도를 log likelihood  라고 한다. - 를 붙인 이유는 딥러닝과 같이 Convex 형태를 만들기 위해서다.

$$ E(\theta) = -ln\ \mathcal L(\theta) = - \sum_{n=0}^{N} ln\ p(x_{n}|\theta) $$
- 위 log likelihood 를 미분하여 최대값 - 를 붙여서 아래로 볼록하게 만들었으니 최소값이 된다)이 되는 $\theta$ 를 구하기 위하여 위의 정규분포 식을 미분 정리하면 다음과 같다. (미분 계산 과정은 생략)

$$ 
	\begin{align}
\frac{\partial}{\partial \theta} E(\theta) \longrightarrow \frac{\partial}{\partial \mu} E(\mu, \sigma) = \frac{1}{\sigma^{2}}(\sum_{n=1}^{N} x_{n} - N\mu)
	\end{align}
$$
- 이때 $\sigma$ (표준편차)는 분모에 있기 때문에 식을 0을 만들 수 없다. 따라서 $\hat\mu = \frac{1}{N}\sum_{n=1}^{N}x_{n}$의 식을 위에 대입 하여 구한다. $\hat\mu$를 구하면  분산도 계산 할  수 있다. 
- 즉, 데이터 샘플이 주어 지고, 이 데이터 샘플의 모수가 정규분포를 따른다고 전제한다면 최대 가능도를 추정하여 샘플이 가르키는 정규분포의 특성 $\mu$와 $\sigma$를 구할 있게 된다.

$$ 
	\begin{align}
 추정모수 =  argmax_{\theta}\ (\frac{\partial L (\theta|X)}{\partial \theta} )
	\end{align}
$$

--> 다항분포 나이브 베이즈 분류라는 방법을 쓰기도 함.


https://scikit-learn.org/1.5/auto_examples/calibration/plot_calibration_curve.html#sphx-glr-auto-examples-calibration-plot-calibration-curve-py


- 이러한 가우시안 분포를 사용함으로써 연속적인 구간에 대한 추정이 가능해진다.
- 그러나 이러한 베이즈 분류 기법은 **순진한(Naive)** 한 전제를 벗어 나지 못한다. 다시 말해서 각 조건 변수의 독립성에 대한 전재를 벗어 날 수 없다. 변수의 독립성 전제는 즉, 선형 분류기의 한계를 벗어 날 수 없다는 뜻이 된다. 
- 선형 분류기의 가장 큰 문제는 "XOR 문제"이다. 다층 차원 사이의 분류 (2 차원 공간에서 보면 간격 사이에 숨어 있는 공간)가 불가능하다는 것이다. 이런 경우 보통 kernel trick 를 사용하기도 한다.
- 또는 다른 상태 조건의 변화를 그래프 네트워크로 표현하여 해결하는 방법을 사용하기도 하는데 이러한 기법을 [[8.2  베이즈 네트워크 분석]] 사용하여 분석하기도 한다.
---


##### 3) EM (Expectation-Maximization algorithm) Algorithm
---

출처: [공돌이의 수학정리노트](https://angeloyeo.github.io/2021/02/08/GMM_and_EM.html)
<center>
<img src="https://raw.githubusercontent.com/angeloyeo/angeloyeo.github.io/master/pics/2021-02-08-GMM_and_EM/pic9.png" width =400 height=300>
</center>

- 1977년 Arthur Dempster, Nan Laird and Donald Rubin 논문에서 처음 등장.
- EM 알고리즘은  MLE를 찾는 방법 중 하나. 모든 샘플 데이터가 주어지지 않은 확률과정을 통해서 데이터가 주어 질 때, 또는 직접 관찰이 불가능하여 해당 분포를 추정할 수 있는 하위 관찰 변수를 통해 모수의 분포를 추정할 때. (쉽게 말해서 현재의 상태를 모를 경우)
- 다음의 조건을 만족하면 EM 알고리즘을 사용할 수 있다.
	1) 관찰하는 확률변수 Y가 우리가 잘 알고 있으며 같은 모수를 사용하는 좀 더 단순한 확률 변수  $X \sim p_{\theta}(x)$ 로 부터 나왔다고 볼 수 있는 경우.
	2) 확률변수 X를 사용한 우도 함수의 최대화를 Y를 사용하는 경우보다 비교적 쉽게 계산할 수 있는 경우.
- 즉, 관측되지 않는 잠재변수(unobserved latent variable)에 의존하는 확률 모델에서 데이터들이 최대우도(maximum likelihood)를 갖는 잠재변수의 분포를 찾아 내는 것


- E-step 과 M-step 라는 두 과정을 연속적인 반복으로 추정해 나갈 수 있다.
- E-step :  주어진  y와 현재 분포($\theta$)의 추정치 $\theta^{k}$  k는 k번째 추정(k번째 데이터로) 분포를 사용하여 다음과 같이 그때의 가능도의 기대값 Q을 계산 할 수 있다. 이를 Q함수라고 한다. 
$$Q(\theta; \theta^{k}) = \mathbb E[log\ p_{\theta}(X)|Y = y,\theta^{(k)}]$$
- 쉽게 생각하면 가정한 초기 분포에서 얻어 질 수 있는 각 클라스 별 기대 우도의 값을 구할 수 있다.
- 이 Q  값의 비율을 통해서 각 클라스에 대한 기대 확률을 구할 수 있다. 
- 해당 클라스에 대한 기대 확률로 봤을 때  관측 데이터로 부터 얻을 수 있는 기대 값을 구할 수 있다.

- M-step: 위에서 계산된 Q함수를 $\theta$에 대하여 최대화 
- 위 과정을 데이터에 대하여 반복한다. 

##### 쉬운 예제

<어떤 동전(상태)인지를 아는 경우>

	 앞뒷 면이 나올 확률이 서로 다른  A, B 두개의 동전이 있다.
	 10번씩 5세트 총 50번의 동전 던지기 (앞 :  H, 뒤: T)를 실시하였다. 
	 결과는 다음과 같다. 

```
1) B : H, T, T, T, H, H, T, H, T, H  B(5H, 5T)
2) A : H, H, H, H, T, H, H, H, H, H  A(9H, 1T)
3) A : H, T, H, H, H, H, H, T, H, H  A(8H, 2T)
4) B : H, T, H, T, T, T, H, H, T, T  B(4H, 6T)
5) A : T, H, H, H, T, H, H, H, T, H  A(7H, 3T)
```
	 이를 이용하여 각 동전에 대한 앞면이 나올 확률을 계산할 수 있다.
	 	 
$$ 
	\begin{align}
		&\hat\theta_{A}=\frac{24}{24 + 6} = 0.80 \\ \\
		&\hat\theta_{B}=\frac{9}{9+11} = 0.45 \\ \\
	\end{align}
$$
<어떤 동전(상태)인지를 모르는 경우>

	어느 동전을 사용하였는지 알 수 없을 때, 어떤 동전인지를 동시에 추정하여야 한다.

```
1) ? : H, T, T, T, H, H, T, H, T, H  ?(5H, 5T)
2) ? : H, H, H, H, T, H, H, H, H, H  ?(9H, 1T)
3) ? : H, T, H, H, H, H, H, T, H, H  ?(8H, 2T)
4) ? : H, T, H, T, T, T, H, H, T, T  ?(4H, 6T)
5) ? : T, H, H, H, T, H, H, H, T, H  ?(7H, 3T)
```

- 초기 설정 : A 동전의 앞면이 나올 확률 p=0.6, B 동전의 앞면이 나올 확률 q=0.5 일지 모른다고 임의로 정한다.

- E-Step
	 1차의 정보를 가지고
	 동전 A를 사용했을 것이라는 초기 설정으로 $a=p^{5}\times (1-p)^{5}=0.6^{5} \times 0.4^{5}$
	 동전 B를 사용했을 것이라는  초기 설정으로 $b=q^{5}\times (1-q)^{5}=0.5^{5} \times 0.5^{5}$  	 
	 (해당 분포일  확률 계산)
	 1차에서 동전 A를 사용했을 때  비율   a(a+b) = 0.449
	 1차에서 동전 B를 사용했을 때  비율   b(a+b) =  0.550
	 
- M-Step

	 이렇게 추정된 비률을 가지고 실제 결과 값에 대한 사후를 추정 계산하면 1차 시에서
	  동전 A인 경우 H 개수 : 0.45 x 5 = 2.25
	  동전 A인 경우 T 개수 : 0.45 x 5 = 2.25
	  동전 B인 경우 H 개수 : 0.55 x 5 = 2.75
	  동전 B인 경우 T 개수 : 0.55 x 5 = 2.75
	  
  E-Step M-Step 을 각각의 회차에 계산하여 Q 기대값을 모두 더하면
	  동전 A인 경우 전체 H 개수 : 21.3
	  동전 A인 경우 전체 T 개수 : 8.6
	  동전 B인 경우 전체 H 개수 : 11.7
	  동전 B인 경우 전체 T 개수 : 8.4
- 이 기대값으로 부터 다시 p 확률을 계산하면 p: 21.3/(21.3+8.6) = 0.71
- q 확률을 계산하면                                     q: 11.7/(11.7+8.4) = 0.58

-  이렇게 다시 유추된  확률을 가지고 위에 과정을 반복하여, p, q가 최대한 안정될 때 까지 반복한다.


=> EM 알고리즘의 활용 : GMM ( Gaussian Mixture Model)


	- MLE
	- EM
	- 베이즈 정리
	- Cross-Entropy
- 모델의 튜닝
	- 하이퍼 파라메터 튜닝 - Grid Searching
	- 입력 변수 (요인의 점검)
